---
title: "Harvest Information Program Season Summary Report"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: cerulean
params:
  comp_path:
    value: x
  year:
    value: x
---

```{r libs, include = FALSE}
library(tidyverse)
library(DT)
library(shiny)
```

```{r import, include = FALSE}

# Define what states, provinces, districts, etc are acceptable address abbreviations
acceptable_residences <-
        c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", "ID",
          "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", "MI", "MN",
          "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC", "ND",
          "OH", "OK", "OR","PA", "RI", "SC", "SD", "TN", "TX", "UT", "VT",
          "VA", "WA", "WV", "WI", "WY", "DC", "HI", "AS", "GU", "MP", "PR", 
          "VI", "UM", "AA", "AE","AP")
```

```{r import2, include = FALSE}
# Run the read function
dl_data <- read_hip(params$comp_path, season = TRUE) 
```

```{r import3, include = FALSE}
# Run the clean function
cleaned_data <-
  dl_data %>% 
  mutate(X2 = stringi::str_enc_toutf8(X2))
  clean()
```

```{r import4, include = FALSE}
# Run the fixDuplicates function
fixed_data <- fixDuplicates(cleaned_data)

# Standardize birth date format
fixed_dates_data <-
  fixed_data %>% 
  mutate(
    birth_date2 =
      ifelse(
        str_detect(birth_date, "^[0-9]{1}\\/"),
        paste0("0", birth_date),
        birth_date),
    birth_date3 =
      ifelse(
        str_length(birth_date2) == 9,
        paste0(
          str_sub(birth_date2, 1, 3),
          "0",
          str_sub(birth_date2, 4, 9)),
        birth_date2)) %>% 
  select(-c("birth_date", "birth_date2")) %>%
  rename(birth_date = birth_date3) %>%
  relocate(birth_date, .before = "issue_date") 
```

```{r import5, include = FALSE}
# Snoop for line shift errors
error_keys <- 
  fixed_dates_data %>% 
  filter(
    !str_detect(birth_date, "^[0-9]{2}\\/[0-9]{2}\\/[0-9]{4}$")) %>% 
  relocate(record_key, .before = "title") %>% 
  relocate(source_file, .before = "record_key") %>%
  select(record_key) %>% 
  pull()

# Correct frame shifts for x number of records
unshifted_data <-
  map_dfr(
    1:length(error_keys),
    ~shiftFix(fixed_data, error_keys[.x], "state", "email", 1)
  ) %>% 
  # Delete the 0s from end of zip
  mutate(zip = str_remove(zip, "0$")) %>%
  mutate(
    birth_date =
      ifelse(
        str_detect(birth_date, "^[0-9]{1}\\/"),
        paste0("0", birth_date),
        birth_date))

rm(fixed_data)
```

```{r import6, include = FALSE}
# Run the proof function
proofed_data <- proof(unshifted_data, year = params$year)
```

```{r import7, include = FALSE}
# Run the correct function
corrected_data <- correct(proofed_data, year = params$year, data = "bag")

# Summarize number of records from Canada
canada_records <-
  unshifted_data %>% 
  filter(state %in% c("AB", "BC", "MB", "NB", "NL", "NT", "NS", "NU", "ON", "PE", "QC", "SK", "YT"))

```

# Introduction

This is a summary report of the `r params$year`-`r params$year+1` season of Harvest Information Program (HIP) data. This year, `r nrow(dl_data)` total records and `r nrow(unshifted_data)` unique records were submitted in `r length(list.files(params$comp_path, recursive = TRUE) %>% as_tibble() %>% transmute(filepath = as.character(value)) %>% mutate(filepath = str_replace(filepath, "TXT", "txt")) %>% filter(str_detect(filepath, "(?<=\\.)txt$")) %>% pull)` files from `r proofed_data %>% select(dl_state) %>% distinct %>% nrow()` states.

Below is a table summarizing the total of number of records per download state.

```{r sum_per_state, echo = FALSE, message = FALSE}

DT::datatable(
  unshifted_data %>% 
    select(dl_state) %>% 
    group_by(dl_state) %>% 
    summarize(sum = n()) %>% 
    ungroup())

```

# Data Checking

## Registration year checking

```{r reg_yr_check, echo = FALSE}
DT::datatable(
  unshifted_data %>% 
    select(registration_yr, dl_state) %>% 
    group_by(registration_yr, dl_state) %>% 
    summarize(n = n()) %>% 
    ungroup())

```

## HuntY response checking

```{r hunty_check, echo = FALSE}
huntcheck <-
  unshifted_data %>% 
  select(hunt_mig_birds, dl_state) %>% 
  group_by(hunt_mig_birds, dl_state) %>% 
  summarize(n = n()) %>% 
  ungroup() 

DT::datatable(huntcheck)

rm(huntcheck)
```

## PII checking

The following records are missing first name, last name, date of birth, address, state, and/or city AND zip. They are not included in the final output table.

```{r record_check, echo = FALSE, fig.align = "center"}
record_check <- 
  dl_data %>%
  rename(
    title = X1,
    firstname = X2,
    middle = X3,
    lastname = X4,
    suffix = X5,
    address = X6,
    city = X7,
    state = X8,
    zip = X9,
    birth_date = X10,
    # Edited X11 to specific .data$X11 to avoid error:
    # "Found an obsolete/platform-specific call in: 'tidy'"
    # "Found the platform-specific device: 'X11'"
    issue_date = X11,
    hunt_mig_birds = X12,
    ducks_bag = X13,
    geese_bag = X14,
    dove_bag = X15,
    woodcock_bag = X16,
    coots_snipe = X17,
    rails_gallinules = X18,
    cranes = X19,
    band_tailed_pigeon = X20,
    brant = X21,
    seaducks = X22,
    registration_yr = X23,
    email = X24) %>%
  # Filter out records if firstname, lastname, city of residence, state of
  # residence, or date of birth are missing -- records discarded because
  # these are needed to identify individuals
  # Discard additional records if they are missing elements of an address
  # and we have no way to resolve it from remaining information (i.e. state
  # from zip)
  filter(
    is.na(firstname)|
      is.na(lastname)|
      is.na(state)|
      is.na(birth_date)|
      is.na(address)|
      (is.na(city)&is.na(zip)))
  

if(nrow(record_check) > 0){
  missing_plot <-
    record_check %>%
    select(firstname, lastname, birth_date, state, address, city, zip) %>%
    # Add an ID per row
    mutate(hunter_id = row_number()) %>%
    # Pivot the field names to long format
    pivot_longer(firstname:zip, names_to = "field") %>%
    # Only keep hunters' fields with NA values
    filter(is.na(value)) %>%
    # Set NA to 1 for plotting
    mutate(value = 1) %>%
    # Make a heat map
    ggplot(aes(x = field, y = as.factor(hunter_id), fill = value)) +
    geom_tile() +
    labs(y = "Hunter ID", x = "Data Field") +
    theme_classic() +
    theme(legend.position = "none",
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

  print(missing_plot)}else{
  message("No records detected with missing PII.")
}
```

There are `r nrow(record_check)` total records with missing PII. Below is a summary of the number of records missing from each HIP file.

```{r pii_by_file, echo = FALSE}
pii_summary <- 
  record_check %>% 
  group_by(source_file) %>% 
  summarize(n = n()) %>% 
  ungroup() %>% 
  left_join(
    dl_data %>% 
      select(source_file) %>% 
      group_by(source_file) %>% 
      mutate(total_rows = n()) %>% 
      ungroup(),
    by = "source_file") %>% 
  mutate(prop = round(n/total_rows, digits = 2)) %>% 
  select(-total_rows) %>% 
  distinct() %>% 
  arrange(desc(prop)) 

DT::datatable(pii_summary)
rm(pii_summary)
rm(dl_data)
```

## Duplicates

### Before fixDuplicates (all 49 states)

```{r b_fd, echo = FALSE, fig.align = "center"}
findDuplicates(cleaned_data)
```

### After fixDuplicates (all 49 states)

```{r a_fd, echo = FALSE}
rm(cleaned_data)
findDuplicates(unshifted_data)

DT::datatable(findDuplicates(unshifted_data, return = "table"))
```

## Strata

```{r stratacheck, echo = FALSE}
DT::datatable(strataCheck(unshifted_data))
```

## Repeated values

### Repeated values across duck, goose, dove, and woodcock bag codes

```{r h_validate, echo = FALSE}
DT::datatable(
  migbirdHarvestData::validate(unshifted_data, type = "horizontal") %>% 
    mutate(prop_repeat = round(prop_repeat, digits = 2)))
```

### Repeated values within duck bag code

```{r v_validate, echo = FALSE}
DT::datatable(migbirdHarvestData::validate(unshifted_data, type = "vertical"))
```

```{r data_sweep, include = FALSE}

# Remove data objects to improve memory use
rm(unshifted_data)
```

# Error Visualizations

## By field

### Before correction

```{r erpf, echo = FALSE, fig.align = "center"}
errorPlot_fields(proofed_data, year = params$year)
```

### After correction

```{r erpf_c, echo = FALSE, fig.align = "center", warning = FALSE}

# Get the order of the fields so that they match the plot above
x_order <-
  proofed_data %>%
  select(errors) %>%
  # Pull errors apart, delimited by hyphens
  separate(errors, into = as.character(c(1:25)), sep = "-") %>%
  # Transform errors into a single column
  pivot_longer(1:25, names_to = "name") %>%
  select(errors = value) %>%
  filter(!is.na(errors)) %>%
  group_by(errors) %>%
  # Count number of correct values
  summarize(count_errors = sum(!is.na(errors))) %>%
  ungroup() %>%
  # Calculate error proportion
  mutate(
    total = nrow(proofed_data),
    proportion = count_errors / nrow(proofed_data)) %>%
  arrange(proportion)

left_join(
  x_order %>% 
    mutate(order = row_number()) %>% 
    select(errors, order), 
  corrected_data %>%
    select(errors) %>%
    # Pull errors apart, delimited by hyphens
    separate(errors, into = as.character(c(1:25)), sep = "-") %>%
    # Transform errors into a single column
    pivot_longer(1:25, names_to = "name") %>%
    select(errors = value) %>%
    filter(!is.na(errors)) %>%
    group_by(errors) %>%
    # Count number of correct values
    summarize(count_errors = sum(!is.na(errors))) %>%
    ungroup(),
  by = "errors") %>%
  mutate(count_errors = ifelse(is.na(count_errors), 0, count_errors)) %>% 
  # Calculate error proportion
  mutate(
    total = nrow(corrected_data),
    proportion = count_errors / nrow(corrected_data)) %>%
  # Plot
  ggplot() +
  geom_bar(
    aes(x = reorder(errors, order), y = proportion),
    stat = "identity") +
  geom_text(
    aes(x = errors, y = proportion, label = count_errors, angle = 90),
    vjust = 0.2, hjust = -0.2) +
  labs(
    x = "Field",
    y = "Error proportion",
    title = "Error proportion per field") +
  scale_y_continuous(expand = expansion(mult = c(-0, 0.25))) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

```

## By state

### Before correction

```{r erps, echo = FALSE, fig.align = "center"}
errorPlot_states(proofed_data)
```

### After correction

```{r erps_c, echo = FALSE, fig.align = "center"}
errorPlot_states(corrected_data)

rm(corrected_data)
```

## By download

### Before correction

```{r erpdl, echo = FALSE}
errorPlot_dl(proofed_data)
```

### After correction

```{r erpdl_c, echo = FALSE}
errorPlot_dl(corrected_data)
```

## Canadian hunters


```{r oosh, echo = FALSE}
DT::datatable(canada_records)
```

## Out-of-state hunters

```{r canadians, echo = FALSE}
outOfStateHunters(proofed_data)
```

## Youth hunters

```{r yh, echo = FALSE}
youthHunters(proofed_data, year = params$year)
```

# Error Exploration

A closer look at common errors and issues within this download's HIP data.

## High error counts

Q: What were the most common fields with errors, and what values caused them?

Most common error fields...

```{r et, echo = FALSE}
et <- errorTable(proofed_data, loc = "none") %>% arrange(desc(error_count))

DT::datatable(et)
```

Values associated with error in `r et$error[1]`

```{r pe_1, echo = FALSE}

if(et$error[1] != "birth_date"){
  err1 <- 
    pullErrors(proofed_data, error = et$error[1], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err1 <- 
    pullErrors(proofed_data, error = et$error[1], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err1)
```

Values associated with error in `r et$error[2]`

```{r pe_2, echo = FALSE}

if(et$error[2] != "birth_date"){
  err2 <- 
    pullErrors(proofed_data, error = et$error[2], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err2 <- 
    pullErrors(proofed_data, error = et$error[2], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err2)
```

Values associated with error in `r et$error[3]`

```{r pe_3, echo = FALSE}

if(et$error[3] != "birth_date"){
  err3 <- 
    pullErrors(proofed_data, error = et$error[3], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err3 <- 
    pullErrors(proofed_data, error = et$error[3], distinct = FALSE) %>% 
    as_tibble() %>%  
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err3)
```

## High error proportions

Q: What states and fields had a proportion of error that exceeded an acceptable threshold (before correction)?

States with more than 1% error

```{r rfs, echo = FALSE}
redFlags(proofed_data, type = "state", threshold = 0.1)
```

Fields with more than 1% error

```{r rff, echo = FALSE}
redFlags(proofed_data, type = "field", threshold = 0.1)
```
