---
title: "Harvest Information Program Download Cycle Report"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: cerulean
params:
  comp_path:
    value: x
  year:
    value: x
---

```{r libs, include = FALSE}
library(tidyverse)
library(DT)
library(shiny)
```

```{r import, include = FALSE}

dl_data <- read_hip(params$comp_path)

cleaned_data <- clean(dl_data)

# Remove original data to improve memory use
rm(dl_data)

fixed_data <- fixDuplicates(cleaned_data)
fxd <- fixed_data$fixed_duplicates %>% as_tibble()
rm(fixed_data)

proofed_data <- proof(fxd, year = params$year)

corrected_data <- correct(proofed_data, year = params$year)

```

# Introduction

This is a report of download cycle `r proofed_data %>% select(dl_cycle) %>% distinct %>% pull`. This cycle, `r nrow(proofed_data)` records were submitted from `r proofed_data %>% select(dl_state) %>% distinct %>% nrow()` states.

Below is a table summarizing the total of number of records per download state.

```{r sum_per_state, echo = FALSE, message = FALSE}

DT::datatable(cleaned_data %>% 
                select(dl_state) %>% 
                group_by(dl_state) %>% 
                summarize(sum = n()) %>% 
                ungroup())

```

# Data Checking

## Duplicates

### Before fixDuplicates (all 49 states)

```{r b_fd, echo = FALSE}
findDuplicates(cleaned_data)

DT::datatable(findDuplicates(cleaned_data, return = "table"))
```

### Before fixDuplicates (only permit states)

Permit states include AK, AZ, CO, KS, MN, MT, ND, NM, OK, OR, SD, TX, UT, WA, and WY.

```{r b_perms, echo = FALSE}
perm_states <- 
  c("AK", "AZ", "CO", "KS", "MN", "MT", "ND", "NM", "OK", "OR", "SD", "TX", 
    "UT", "WA", "WY")

findDuplicates(cleaned_data %>% filter(dl_state %in% perm_states))

DT::datatable(findDuplicates(cleaned_data %>% filter(dl_state %in% perm_states), return = "table"))
```

### After fixDuplicates (all 49 states)

```{r a_fd, echo = FALSE}
findDuplicates(fxd)

DT::datatable(findDuplicates(fxd, return = "table"))
```

### After fixDuplicates (only permit states)

Permit states include AK, AZ, CO, KS, MN, MT, ND, NM, OK, OR, SD, TX, UT, WA, and WY.

```{r a_perms, echo = FALSE}
findDuplicates(fxd %>% filter(dl_state %in% perm_states))

DT::datatable(findDuplicates(fxd %>% filter(dl_state %in% perm_states), return = "table"))
```

## Strata

```{r stratacheck, echo = FALSE}
DT::datatable(strataCheck(fxd))
```

## Repeated values

### Horizontal

```{r h_validate, echo = FALSE}
DT::datatable(migbirdHarvestData::validate(fxd, type = "horizontal"))
```

### Vertical

```{r v_validate, echo = FALSE}
DT::datatable(migbirdHarvestData::validate(fxd, type = "vertical"))
```

```{r data_sweep, include = FALSE}

# Remove data objects to improve memory use
rm(cleaned_data)
rm(fxd)
rm(perm_states)
```

# Error Visualizations

## By field

### Before correction

```{r erpf, echo = FALSE}
errorPlot_fields(proofed_data, year = params$year)
```

### After correction

```{r erpf_c, echo = FALSE}
errorPlot_fields(corrected_data, year = params$year)
```

## By state

### Before correction

```{r erps, echo = FALSE}
errorPlot_states(proofed_data)
```

### After correction

```{r erps_c, echo = FALSE}
errorPlot_states(corrected_data)
```

# Error Exploration

Let's take a closer look at common errors and issues within this download's HIP data.

## High error counts

Q: What were the most common fields with errors, and what values caused them?

Most common error fields...

```{r et, echo = FALSE}
et <- errorTable(proofed_data, loc = "none") %>% arrange(desc(error_count))

DT::datatable(et)
```

Values associated with error in `r et$error[1]`

```{r pe_1, echo = FALSE}
err1 <- 
  pullErrors(proofed_data, error = et$error[1]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err1)
```

Values associated with error in `r et$error[2]`

```{r pe_2, echo = FALSE}
err2 <- 
  pullErrors(proofed_data, error = et$error[2]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err2)
```

Values associated with error in `r et$error[3]`

```{r pe_3, echo = FALSE}
err3 <- 
  pullErrors(proofed_data, error = et$error[3]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err3)
```

## High error proportions

Q: What states and fields had a proportion of error that exceeded an acceptable threshold (before correction)?

States with more than 1% error

```{r rfs, echo = FALSE}
redFlags(proofed_data, type = "state", threshold = 0.1)
```

Fields with more than 1% error

```{r rff, echo = FALSE}
redFlags(proofed_data, type = "field", threshold = 0.1)
```
