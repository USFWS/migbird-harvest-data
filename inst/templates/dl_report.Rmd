---
title: "Harvest Information Program Download Cycle Report"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: cerulean
params:
  comp_path:
    value: x
  final_path:
    value: x
  future_path:
    value: x
  dl:
    value: x
  year:
    value: x
---

```{r libs, include = FALSE}
library(tidyverse)
library(data.table)
library(DT)
library(shiny)
library(stringi)
```

```{r import, include = FALSE}

dl_data <- read_hip(params$comp_path) %>% mutate(dl_cycle = params$dl)

# Standardize birth date format
fixed_dates_data <-
  dl_data %>% 
  mutate(
    birth_date2 =
      ifelse(
        str_detect(birth_date, "^[0-9]{1}\\/"),
        paste0("0", birth_date),
        birth_date),
    birth_date3 =
      ifelse(
        str_length(birth_date2) == 9,
        paste0(
          str_sub(birth_date2, 1, 3),
          "0",
          str_sub(birth_date2, 4, 9)),
        birth_date2)) %>% 
  select(-c("birth_date", "birth_date2")) %>%
  rename(birth_date = birth_date3) %>%
  relocate(birth_date, .before = "issue_date") 

# Snoop for line shift errors
error_keys <- 
  fixed_dates_data %>% 
  filter(
    !str_detect(
      birth_date, "^[0-9]{2}\\/[0-9]{2}\\/[0-9]{4}$")) %>% 
  relocate(record_key, .before = "title") %>% 
  relocate(source_file, .before = "record_key") %>%
  select(record_key) %>% 
  pull()

# Correct frame shifts for x number of records
if(length(error_keys) > 0){
  unshifted <-
    map_dfr(
      1:length(error_keys),
      ~shiftFix(fixed_dates_data, error_keys[.x], "state", "email", 1)
    ) %>% 
    # Delete the 0s from end of zip
    mutate(zip = str_remove(zip, "0$")) %>%
    mutate(
      birth_date =
        ifelse(
          str_detect(birth_date, "^[0-9]{1}\\/"),
          paste0("0", birth_date),
          birth_date))
}else{
  unshifted <- NULL
}

rm(error_keys)

unshifted_data <-
  fixed_dates_data %>%
  filter(!record_key %in% unshifted$record_key) %>%
  bind_rows(unshifted) 

rm(fixed_dates_data)
rm(unshifted)

cleaned_data <- clean(unshifted_data)

rm(unshifted_data)

current_data <- issueCheck(cleaned_data, params$year, write = F)

fixed_data <- fixDuplicates(current_data)

proofed_data <- proof(fixed_data, year = params$year)

# Read in the completed download data (for better/more accurate figures and tables)
final_data <-
  map_df(
    1:length(list.files(params$final_path)),
    ~fread(
      paste0(params$final_path, list.files(params$final_path)[.x]),
      colClasses = rep("character", 37),
      na.strings = "") %>% 
      select(1:27) %>% 
      rename(
        zip = postal_code,
        ducks_bag = Q_ducks,
        geese_bag = Q_geese,
        dove_bag = Q_doves,
        woodcock_bag = Q_woodcock,
        coots_snipe = Q_coot_snipe,
        rails_gallinules = Q_rail_gallinule,
        cranes = Q_cranes,
        band_tailed_pigeon = Q_bt_pigeons,
        brant = Q_brant,
        seaducks = Q_seaducks)) %>% 
  proof(., year = params$year) %>% 
  mutate(
    # Add the download date as a column
    dl_date =
      str_extract(source_file, "(?<=[A-Z]{2})[0-9]{8}(?=\\.txt)"),
    # Add the download cycle as a column
    dl_cycle = params$dl)

# Summarize number of records from Canada
canada_records <-
  final_data %>% 
  select(state) %>% 
  filter(state %in% c("AB", "BC", "MB", "NB", "NL", "NT", "NS", "NU", "ON", "PE", "QC", "SK", "YT")) %>% 
  nrow()

# Summarize number of bad zip codes
zip_check <-
  final_data %>% 
  filter(!state %in% c("AB", "BC", "MB", "NB", "NL", "NT", "NS", "NU", "ON", "PE", "QC", "SK", "YT")) %>% 
  mutate(zipPrefix = str_extract(zip, "^[0-9]{3}")) %>%
  left_join(
    zip_code_ref %>%
      select(zipPrefix, zipState = state),
    by = "zipPrefix") %>%
  filter(state != zipState) %>% 
  nrow()

```

# Introduction

This is a report of download cycle `r proofed_data %>% select(dl_cycle) %>% distinct %>% pull`. This cycle, `r sumLines(params$comp_path)` lines of data (`r nrow(final_data)` unique records) were submitted in `r length(list.files(params$comp_path, recursive = F, pattern = "*\\.txt$", ignore.case = TRUE))` files from `r proofed_data %>% select(dl_state) %>% distinct %>% nrow()` states. A total of `r canada_records` records were received from Canada, and `r zip_check` records did not have a zip code that matched the address state.

```{r data_sweep, include = FALSE}

rm(canada_records)
rm(zip_check)
```


Below is a table summarizing the total of number of records per download state.

```{r sum_per_state, echo = FALSE, message = FALSE}

DT::datatable(
  final_data %>% 
    select(dl_state) %>% 
    group_by(dl_state) %>% 
    summarize(sum = n()) %>% 
    ungroup())

```

# Data Checking

## Registration year checking

### Summary of registration_yr

```{r reg_yr_check, echo = FALSE}
reg_yr_summary <-
  final_data %>% 
    select(registration_yr, dl_state) %>% 
    # Filter out records from this year since we know they are good
    filter(registration_yr != as.character(params$year)) %>% 
    group_by(registration_yr, dl_state) %>% 
    summarize(n = n()) %>% 
    ungroup()

if(nrow(reg_yr_summary) > 0){
  DT::datatable(reg_yr_summary)
}else{
  message(paste0("All registration years = ", as.character(params$year), "."))
}

rm(reg_yr_summary)
```

### Records changed for this season and copied for next season

Records below had their registration_yr edited to be compatible for this HIP season and were also copied and exported for next HIP season.

```{r reg_yr_check2, echo = FALSE}
twoseasonstates <-
  licenses_ref %>%
  filter(category == "2 season") %>%
  select(state) %>%
  pull()

issue_assignments <-
  cleaned_data %>%
  left_join(
    licenses_ref %>%
      rename(dl_state = state),
    by = "dl_state") %>%
  # Filter out bad issue_date values
  filter(issue_date != "00/00/0000") %>%
  mutate(
    issue_id =
      case_when(
        dl_state %in% twoseasonstates &
          registration_yr == as.character(params$year + 1) &
          mdy(issue_date) %within%
          interval(issue_start, last_day_migbird_hunting) ~ "copy",
        dl_state %in% twoseasonstates &
          registration_yr == as.character(params$year) &
          mdy(issue_date) > last_day_migbird_hunting ~ "postpone",
        dl_state == "MS" &
              mdy(issue_date) %within%
              interval(MS_firstday, MS_lastday) ~ "copy",
        # Postpone all other future registration_yr values, for all states
        registration_yr == as.character(params$year + 1) ~ "postpone",
        TRUE ~ "nochange")) %>%
  select(-c("hunting_season", "issue_start", "issue_end",
            "last_day_migbird_hunting", "category"))

current_records <-
  issue_assignments %>%
  filter(issue_id != "postpone") %>%
  mutate(
    registration_yr =
      ifelse(
        issue_id == "copy",
        as.character(as.numeric(registration_yr)-1),
        registration_yr)) %>%
  filter(issue_id == "copy") %>% 
  select(-issue_id) 

if(nrow(current_records) > 0){
  current_summary <- 
    current_records %>% 
    group_by(dl_state, registration_yr) %>% 
    summarize(n = n()) %>% 
    ungroup() %>% 
    arrange(desc(n))
  
  DT::datatable(current_summary)
}else{
  message("No records to change/copy.")
}

rm(current_records)
rm(issue_assignments)
rm(twoseasonstates)

```

### Records set aside for next season

Records below have an issue_date after the end of migratory bird hunting for that state and where thus set aside for next year.

```{r reg_yr_check3, echo = FALSE}

if(str_detect(params$future_path, "\\/$") == FALSE){
  params$future_path <- paste0(params$future_path, "/")}

future_file <- paste0("DL", params$dl, "_future_data.csv")

if(future_file %in% list.files(params$future_path) == TRUE){
  future_data <-
    read_csv(paste0(params$future_path, future_file))
  
  future_summary <- 
    future_data %>% 
    group_by(dl_state, registration_yr, issue_id) %>% 
    summarize(n = n()) %>% 
    ungroup() %>% 
    arrange(desc(n))
  
  DT::datatable(future_summary)
}else{
  message("No records to postpone.")
}

rm(future_data)
rm(future_summary)
rm(future_file)

```

## HuntY response checking

```{r hunty_check, echo = FALSE}
huntcheck <-
  final_data %>% 
  select(hunt_mig_birds, dl_state) %>% 
  group_by(dl_state) %>% 
  mutate(total_state_n = n()) %>% 
  ungroup() %>% 
  filter(hunt_mig_birds != 2) %>% 
  group_by(hunt_mig_birds, dl_state) %>% 
  summarize(
    n = n(),
    prop = round(n()/total_state_n, 2)) %>% 
  ungroup() %>% 
  distinct() %>% 
  arrange(desc(prop))

if(nrow(huntcheck) > 0){
  DT::datatable(huntcheck)
  }else{
  message("All HuntY = 2.")
}

rm(huntcheck)
```

## PII checking

The following records are missing first name, last name, date of birth, address, state, and/or city AND zip. They are not included in the final output table.

```{r record_check, echo = FALSE, fig.align = "center"}
record_check <- 
  dl_data %>%
  # Filter out records if firstname, lastname, city of residence, state of
  # residence, or date of birth are missing -- records discarded because
  # these are needed to identify individuals
  # Discard additional records if they are missing elements of an address
  # and we have no way to resolve it from remaining information (i.e. state
  # from zip)
  filter(
    is.na(firstname)|
      is.na(lastname)|
      is.na(state)|
      is.na(birth_date)|
      is.na(address)|
      (is.na(city)&is.na(zip)))
  
if(nrow(record_check) > 0){
  missing_plot <-
    record_check %>%
    select(firstname, lastname, birth_date, state, address, city, zip) %>%
    # Add an ID per row
    mutate(hunter_id = row_number()) %>%
    # Pivot the field names to long format
    pivot_longer(firstname:zip, names_to = "field") %>%
    # Only keep hunters' fields with NA values
    filter(is.na(value)) %>%
    # Set NA to 1 for plotting
    mutate(value = 1) %>%
    # Make a heat map
    ggplot(aes(x = field, y = as.factor(hunter_id), fill = value)) +
    geom_tile() +
    labs(y = "Hunter ID", x = "Data Field") +
    theme_classic() +
    theme(legend.position = "none",
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

  print(missing_plot)}else{
  message("No records detected with missing PII.")
}
```

There are `r nrow(record_check)` total records with missing PII. Below is a summary of the number of records missing from each HIP file.

```{r pii_by_file, echo = FALSE}
pii_summary <- 
  record_check %>% 
  group_by(source_file) %>% 
  summarize(n = n()) %>% 
  ungroup() %>% 
  left_join(
    dl_data %>% 
      select(source_file) %>% 
      group_by(source_file) %>% 
      mutate(total_rows = n()) %>% 
      ungroup(),
    by = "source_file") %>% 
  mutate(prop = round(n/total_rows, digits = 2)) %>% 
  select(-total_rows) %>% 
  distinct() %>% 
  arrange(desc(prop)) 

DT::datatable(pii_summary)
rm(pii_summary)
rm(dl_data)
```

## Duplicates

### Before fixDuplicates (all 49 states)

```{r b_fd, echo = FALSE, fig.align = "center"}
findDuplicates(current_data)

rm(current_data)
```

### After fixDuplicates (all 49 states)

```{r a_fd, echo = FALSE, fig.align = "center"}
findDuplicates(fixed_data)

DT::datatable(findDuplicates(fixed_data, return = "table"))

rm(fixed_data)
```

## Strata

```{r stratacheck, echo = FALSE}
DT::datatable(
  strataCheck(final_data),
  extensions = "Buttons",
  options = 
    list(
      dom = "Bfrtip",
      buttons = c("csv", "excel", "pdf"))
  )
```

## Repeated values

### Repeated values across duck, goose, and snipe_coot bag codes

The table below shows how many records had horizontal repetition across the duck, goose, and snipe_coot columns. For each source file, the value repeated is indicated (h_value), the number of records with horizontal repetition in the file are reported (h_rep), the total number of records per file are reported (h_total), and the proportion of the file with horizontal repetition is indicated (prop_repeat).

```{r h_validate, echo = FALSE}
DT::datatable(
  migbirdHIP::validate(final_data, type = "horizontal") %>% 
    mutate(prop_repeat = round(prop_repeat, digits = 2)))
```

### Repeated values within duck bag code

The table below shows how many records per file had the same value for all rows of the ducks_bag column. The v_repeated field indicates total count.

```{r v_validate, echo = FALSE}
DT::datatable(migbirdHIP::validate(final_data, type = "vertical"))
```

# Error Visualizations

## By field

### Before correction

```{r erpf, echo = FALSE, fig.align = "center"}
errorPlot_fields(proofed_data, year = params$year, youth = T)
```

### After correction

```{r erpf_c, echo = FALSE, fig.align = "center", warning = FALSE}

# Get the order of the fields so that they match the plot above
x_order <-
  proofed_data %>%
  select(errors) %>%
  # Pull errors apart, delimited by hyphens
  separate(errors, into = as.character(c(1:25)), sep = "-") %>%
  # Transform errors into a single column
  pivot_longer(1:25, names_to = "name") %>%
  select(errors = value) %>%
  filter(!is.na(errors)) %>%
  group_by(errors) %>%
  # Count number of correct values
  summarize(count_errors = sum(!is.na(errors))) %>%
  ungroup() %>%
  # Calculate error proportion
  mutate(
    total = nrow(proofed_data),
    proportion = count_errors / nrow(proofed_data)) %>%
  arrange(proportion) %>% 
  select(errors) %>% 
  mutate(order = row_number())

table_1 <-
  final_data %>%
  mutate(
    birth_year = str_extract(birth_date, "(?<=\\/)[0-9]{4}$"),
    special =
      ifelse(
        birth_year > params$year - 16,
        "Youth Hunter",
        NA)) %>%
  select(errors, special) %>%
  # Pull errors apart, delimited by hyphens
  separate(errors, into = as.character(c(1:25)), sep = "-") %>%
  # Transform errors into a single column
  pivot_longer(1:25, names_to = "name") %>%
  select(errors = value, special) %>%
  filter(!is.na(errors))

# Step 2: table of errors with proportions calculated -- the youth
# errors must be row bound in
table_2 <-
  table_1 %>%
  group_by(errors) %>%
  # Count number of correct and incorrect values
  summarize(count_errors = sum(!is.na(errors))) %>%
  ungroup() %>%
  filter(errors != "birth_date") %>%
  bind_rows(
    table_1 %>%
      group_by(errors, special) %>%
      summarize(count_errors = sum(!is.na(errors))) %>%
      ungroup() %>%
      filter(errors == "birth_date")) %>%
  # Calculate error proportion
  mutate(
    total = nrow(final_data),
    proportion = count_errors / nrow(final_data))

# Labels for bar plot (birth_date color stack doesn't cooperate with
# positioning 2 labels, so we only label that field once at the top of
# the bar)
barlabels <-
  table_2 %>%
  select(-c("special", "total")) %>%
  group_by(errors) %>%
  mutate(
    count_errors = sum(count_errors),
    proportion = sum(proportion)) %>%
  ungroup()

# Plot
x_order %>%
  left_join(table_2, by = "errors") %>% 
  mutate(
    proportion = ifelse(is.na(proportion), 0, proportion),
    total = ifelse(is.na(total), 0, total)) %>%
  group_by(errors) %>% 
  mutate(
    count_errors = sum(count_errors),
    cumulative_prop = sum(proportion)) %>% 
  ungroup() %>% 
  ggplot() +
  geom_bar(
    aes(x = reorder(errors, order), y = proportion, fill = special),
    stat = "identity") +
  geom_text(
    aes(x = errors,
        y = cumulative_prop,
        label = count_errors,
        angle = 90),
    vjust = 0.2, hjust = -0.2) +
  labs(
    x = "Field",
    y = "Error proportion",
    title = "Error proportion per field",
    fill = "Specifics") +
  scale_y_continuous(expand = expansion(mult = c(-0, 0.25))) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  scale_fill_discrete(labels = "Youth Hunter", breaks = "Youth Hunter")

rm(x_order) 
rm(table_1)
rm(table_2)
rm(barlabels)

```

## By state

### Before correction

```{r erps, echo = FALSE, fig.align = "center"}
errorPlot_states(proofed_data)
```

### After correction

```{r erps_c, echo = FALSE, fig.align = "center"}
errorPlot_states(final_data)

rm(final_data)
```

# Error Exploration

The tables below show a closer look at errors and issues within this download's HIP data. Note that some of these values may have been corrected; what is being displayed are the errors that were caught.

## High error counts

Q: What were the most common fields with errors, and what values caused them?

Most common error fields...

```{r et, echo = FALSE}
et <- errorTable(proofed_data, loc = "none") %>% arrange(desc(error_count))

DT::datatable(et)
```

Values associated with error in `r et$error[1]`

```{r pe_1, echo = FALSE}

if(et$error[1] != "birth_date"){
  err1 <- 
    pullErrors(proofed_data, error = et$error[1], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err1 <- 
    pullErrors(proofed_data, error = et$error[1], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err1)
```

Values associated with error in `r et$error[2]`

```{r pe_2, echo = FALSE}

if(et$error[2] != "birth_date"){
  err2 <- 
    pullErrors(proofed_data, error = et$error[2], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err2 <- 
    pullErrors(proofed_data, error = et$error[2], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err2)
```

Values associated with error in `r et$error[3]`

```{r pe_3, echo = FALSE}

if(et$error[3] != "birth_date"){
  err3 <- 
    pullErrors(proofed_data, error = et$error[3], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err3 <- 
    pullErrors(proofed_data, error = et$error[3], distinct = FALSE) %>% 
    as_tibble() %>%  
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err3)
```

## High error proportions

Q: What states and fields had a proportion of error that exceeded an acceptable threshold (before correction)?

States with more than 1% error

```{r rfs, echo = FALSE}
redFlags(proofed_data, type = "state", threshold = 0.1)
```

Fields with more than 1% error

```{r rff, echo = FALSE}
redFlags(proofed_data, type = "field", threshold = 0.1)
```
