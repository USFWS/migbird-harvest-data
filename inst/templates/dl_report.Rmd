---
title: "Harvest Information Program Download Cycle Report"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: cerulean
params:
  comp_path:
    value: x
  dl:
    value: x
  year:
    value: x
---

```{r libs, include = FALSE}
library(tidyverse)
library(DT)
library(shiny)
```

```{r import, include = FALSE}

acceptable_49_dl_states <-
        c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", "ID",
          "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", "MI", "MN",
          "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC", "ND",
          "OH", "OK", "OR","PA", "RI", "SC", "SD", "TN", "TX", "UT", "VT",
          "VA", "WA", "WV", "WI", "WY")

dl_data <- read_hip(params$comp_path) %>% mutate(dl_cycle = params$dl)

cleaned_data <- clean(dl_data)

# Remove original data to improve memory use
rm(dl_data)

fixed_data <- fixDuplicates(cleaned_data)

proofed_data <- proof(fixed_data, year = params$year)

corrected_data <- correct(proofed_data, year = params$year, data = "bag")

```

# Introduction

This is a report of download cycle `r proofed_data %>% select(dl_cycle) %>% distinct %>% pull`. This cycle, `r sumLines(params$comp_path)` lines of data (`r nrow(fixed_data)` unique records) were submitted in `r length(list.files(params$comp_path) %>% as_tibble() %>% transmute(filepath = as.character(value)) %>% mutate(filepath = str_replace(filepath, "TXT", "txt")) %>% filter(str_detect(filepath, "(?<=\\.)txt$")) %>% pull)` files from `r proofed_data %>% select(dl_state) %>% distinct %>% nrow()` states.

Below is a table summarizing the total of number of records per download state.

```{r sum_per_state, echo = FALSE, message = FALSE}

DT::datatable(cleaned_data %>% 
                select(dl_state) %>% 
                group_by(dl_state) %>% 
                summarize(sum = n()) %>% 
                ungroup())

```

# Data Checking

## Records checking

The following records are missing first name, last name, date of birth, address, city, state of residence, and/or state AND zip.

```{r record_check, echo = FALSE}
record_check <- 
  dl_data %>%
    rename(
      title = X1,
      firstname = X2,
      middle = X3,
      lastname = X4,
      suffix = X5,
      address = X6,
      city = X7,
      state = X8,
      zip = X9,
      birth_date = X10,
      # Edited X11 to specific .data$X11 to avoid error:
      # "Found an obsolete/platform-specific call in: 'tidy'"
      # "Found the platform-specific device: 'X11'"
      issue_date = .data$X11,
      hunt_mig_birds = X12,
      ducks_bag = X13,
      geese_bag = X14,
      dove_bag = X15,
      woodcock_bag = X16,
      coots_snipe = X17,
      rails_gallinules = X18,
      cranes = X19,
      band_tailed_pigeon = X20,
      brant = X21,
      seaducks = X22,
      registration_yr = X23,
      email = X24) %>%
    # Filter out records if firstname, lastname, city of residence, state of
    # residence, or date of birth are missing -- records discarded because
    # these are needed to identify individuals
    filter(!is.na(firstname)) %>%
    filter(!is.na(lastname)) %>%
    filter(!is.na(state)) %>%
    filter(!is.na(birth_date)) %>%
    # Discard additional records if they are missing elements of an address
    # and we have no way to resolve it from remaining information (i.e. state
    # from zip)
    filter(!is.na(address)) %>%
    filter(!is.na(city)) %>%
    filter(!is.na(state) & !is.na(zip))

DT::datatable(record_check)
```

## State check

```{r state_check, echo = FALSE}
rm(record_check)

state_check <-
  clean_data %>% 
  select(state) %>% 
  group_by(state) %>% 
  summarize(n_records = n()) %>% 
  ungroup() %>% 
  mutate(valid = ifelse(!(state %in% acceptable_49_dl_states), "invalid", NA)) %>% 
  arrange(valid)

DT::datatable(state_check)
```

## Duplicates

### Before fixDuplicates (all 49 states)

```{r b_fd, echo = FALSE}
rm(state_check)

findDuplicates(cleaned_data)

DT::datatable(findDuplicates(cleaned_data, return = "table"))
```

### After fixDuplicates (all 49 states)

```{r a_fd, echo = FALSE}
findDuplicates(fixed_data)

DT::datatable(findDuplicates(fixed_data, return = "table"))
```

## Strata

```{r stratacheck, echo = FALSE}
DT::datatable(strataCheck(fixed_data))
```

## All 0 records

```{r all0, echo = FALSE}
all0s <- 
  fixed_data %>% 
  filter(
    ducks_bag == "0" &
      geese_bag == "0" &
      dove_bag == "0" &
      woodcock_bag == "0" &
      coots_snipe == "0" &
      rails_gallinules == "0" &
      cranes == "0" &
      band_tailed_pigeon == "0" &
      brant == "0" &
      seaducks == "0")

DT::datatable(all0s)
```

## Repeated values

### Horizontal

```{r h_validate, echo = FALSE}
DT::datatable(migbirdHarvestData::validate(fixed_data, type = "horizontal"))
```

### Vertical

```{r v_validate, echo = FALSE}
DT::datatable(migbirdHarvestData::validate(fixed_data, type = "vertical"))
```

```{r data_sweep, include = FALSE}

# Remove data objects to improve memory use
rm(cleaned_data)
rm(fixed_data)
```

# Error Visualizations

## By field

### Before correction

```{r erpf, echo = FALSE}
errorPlot_fields(proofed_data, year = params$year)
```

### After correction

```{r erpf_c, echo = FALSE}
errorPlot_fields(corrected_data, year = params$year)
```

## By state

### Before correction

```{r erps, echo = FALSE}
errorPlot_states(proofed_data)
```

### After correction

```{r erps_c, echo = FALSE}
errorPlot_states(corrected_data)
```

# Error Exploration

Let's take a closer look at common errors and issues within this download's HIP data.

## High error counts

Q: What were the most common fields with errors, and what values caused them?

Most common error fields...

```{r et, echo = FALSE}
et <- errorTable(proofed_data, loc = "none") %>% arrange(desc(error_count))

DT::datatable(et)
```

Values associated with error in `r et$error[1]`

```{r pe_1, echo = FALSE}
err1 <- 
  pullErrors(proofed_data, error = et$error[1]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err1)
```

Values associated with error in `r et$error[2]`

```{r pe_2, echo = FALSE}
err2 <- 
  pullErrors(proofed_data, error = et$error[2]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err2)
```

Values associated with error in `r et$error[3]`

```{r pe_3, echo = FALSE}
err3 <- 
  pullErrors(proofed_data, error = et$error[3]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err3)
```

## High error proportions

Q: What states and fields had a proportion of error that exceeded an acceptable threshold (before correction)?

States with more than 1% error

```{r rfs, echo = FALSE}
redFlags(proofed_data, type = "state", threshold = 0.1)
```

Fields with more than 1% error

```{r rff, echo = FALSE}
redFlags(proofed_data, type = "field", threshold = 0.1)
```
