---
title: "Harvest Information Program Download Cycle Report"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: cerulean
params:
  comp_path:
    value: x
  final_path:
    value: x
  dl:
    value: x
  year:
    value: x
---

```{r libs, include = FALSE}
library(tidyverse)
library(data.table)
library(DT)
library(shiny)
library(stringi)
```

```{r import, include = FALSE}

dl_data <- read_hip(params$comp_path) %>% mutate(dl_cycle = params$dl)

# Standardize birth date format
fixed_dates_data <-
  dl_data %>% 
  mutate(
    birth_date2 =
      ifelse(
        str_detect(birth_date, "^[0-9]{1}\\/"),
        paste0("0", birth_date),
        birth_date),
    birth_date3 =
      ifelse(
        str_length(birth_date2) == 9,
        paste0(
          str_sub(birth_date2, 1, 3),
          "0",
          str_sub(birth_date2, 4, 9)),
        birth_date2)) %>% 
  select(-c("birth_date", "birth_date2")) %>%
  rename(birth_date = birth_date3) %>%
  relocate(birth_date, .before = "issue_date") 

# Snoop for line shift errors
error_keys <- 
  fixed_dates_data %>% 
  filter(
    !str_detect(
      birth_date, "^[0-9]{2}\\/[0-9]{2}\\/[0-9]{4}$")) %>% 
  relocate(record_key, .before = "title") %>% 
  relocate(source_file, .before = "record_key") %>%
  select(record_key) %>% 
  pull()

# Correct frame shifts for x number of records
if(length(error_keys) > 0){
  unshifted <-
    map_dfr(
      1:length(error_keys),
      ~shiftFix(fixed_dates_data, error_keys[.x], "state", "email", 1)
    ) %>% 
    # Delete the 0s from end of zip
    mutate(zip = str_remove(zip, "0$")) %>%
    mutate(
      birth_date =
        ifelse(
          str_detect(birth_date, "^[0-9]{1}\\/"),
          paste0("0", birth_date),
          birth_date))
}else{
  unshifted <- NULL
}

rm(error_keys)

unshifted_data <-
  fixed_dates_data %>%
  filter(!record_key %in% unshifted$record_key) %>%
  bind_rows(unshifted) 

rm(fixed_dates_data)
rm(unshifted)

cleaned_data <- clean(unshifted_data)

rm(unshifted_data)

current_data <- issueCheck(cleaned_data, params$year, write = F)

fixed_data <- fixDuplicates(current_data)

proofed_data <- proof(fixed_data, year = params$year)

# Read in the completed download data (for better/more accurate figures and tables)
final_data <-
  map_df(
    1:length(list.files(params$final_path)),
    ~fread(
      paste0(params$final_path, list.files(params$final_path)[.x]),
      colClasses = rep("character", 37),
      na.strings = "") %>% 
      select(1:27) %>% 
      rename(
        zip = postal_code,
        ducks_bag = Q_ducks,
        geese_bag = Q_geese,
        dove_bag = Q_doves,
        woodcock_bag = Q_woodcock,
        coots_snipe = Q_coot_snipe,
        rails_gallinules = Q_rail_gallinule,
        cranes = Q_cranes,
        band_tailed_pigeon = Q_bt_pigeons,
        brant = Q_brant,
        seaducks = Q_seaducks)) %>% 
  proof(., year = params$year) %>% 
  mutate(
    # Add the download date as a column
    dl_date =
      str_extract(source_file, "(?<=[A-Z]{2})[0-9]{8}(?=\\.txt)"),
    # Add the download cycle as a column
    dl_cycle = params$dl)

# Summarize number of records from Canada
canada_records <-
  final_data %>% 
  select(state) %>% 
  filter(state %in% c("AB", "BC", "MB", "NB", "NL", "NT", "NS", "NU", "ON", "PE", "QC", "SK", "YT")) %>% 
  nrow()

# Summarize number of bad zip codes
zip_check <-
  final_data %>% 
  filter(!state %in% c("AB", "BC", "MB", "NB", "NL", "NT", "NS", "NU", "ON", "PE", "QC", "SK", "YT")) %>% 
  mutate(zipPrefix = str_extract(zip, "^[0-9]{3}")) %>%
  left_join(
    zip_code_ref %>%
      select(zipPrefix, zipState = state),
    by = "zipPrefix") %>%
  filter(state != zipState) %>% 
  nrow()

```

# Introduction

This is a report of download cycle `r proofed_data %>% select(dl_cycle) %>% distinct %>% pull`. This cycle, `r sumLines(params$comp_path)` lines of data (`r nrow(final_data)` unique records) were submitted in `r length(list.files(params$comp_path, recursive = F, pattern = "*\\.txt$", ignore.case = TRUE))` files from `r proofed_data %>% select(dl_state) %>% distinct %>% nrow()` states. A total of `r canada_records` records were received from Canada, and `r zip_check` records did not have a zip code that matched the address state.

```{r data_sweep, include = FALSE}

rm(canada_records)
rm(zip_check)
```


Below is a table summarizing the total of number of records per download state.

```{r sum_per_state, echo = FALSE, message = FALSE}

DT::datatable(
  final_data %>% 
    select(dl_state) %>% 
    group_by(dl_state) %>% 
    summarize(sum = n()) %>% 
    ungroup())

```

# Data Checking

## Registration year checking

### Summary of registration_yr

```{r reg_yr_check, echo = FALSE}
DT::datatable(
  final_data %>% 
    select(registration_yr, dl_state) %>% 
    group_by(registration_yr, dl_state) %>% 
    summarize(n = n()) %>% 
    ungroup())

```

### Records changed for this season and copied for next season

Records below had their registration_yr edited to be compatible for this HIP season and were also copied and exported for next HIP season.

```{r reg_yr_check2, echo = FALSE}
twoseasonstates <-
  licenses_ref %>%
  filter(category == "2 season") %>%
  select(state) %>%
  pull()

issue_assignments <-
  cleaned_data %>%
  left_join(
    licenses_ref %>%
      rename(dl_state = state),
    by = "dl_state") %>%
  # Filter out bad issue_date values
  filter(issue_date != "00/00/0000") %>%
  mutate(
    issue_id =
      case_when(
        dl_state %in% twoseasonstates &
          registration_yr == as.character(params$year + 1) &
          mdy(issue_date) %within%
          interval(issue_start, last_day_migbird_hunting) ~ "copy",
        dl_state %in% twoseasonstates &
          registration_yr == as.character(params$year) &
          mdy(issue_date) > last_day_migbird_hunting ~ "postpone",
        dl_state == "MS" &
          mdy(issue_date) %within%
          interval(MS_firstday, last_day_migbird_hunting) ~ "copy",
        TRUE ~ NA_character_)) %>%
  select(-c("hunting_season", "issue_start", "issue_end",
            "last_day_migbird_hunting", "category"))

current_records <-
  issue_assignments %>%
  mutate(
    registration_yr =
      ifelse(
        issue_id == "copy",
        as.character(as.numeric(registration_yr)-1),
        registration_yr)) %>%
  filter(issue_id == "copy") %>% 
  select(-issue_id) 

if(nrow(current_records) > 0){
  current_summary <- 
    current_records %>% 
    group_by(dl_state, registration_yr) %>% 
    summarize(n = n()) %>% 
    ungroup()
  
  DT::datatable(current_summary)
}else{
  message("No records to change/copy.")
}

rm(current_records)

```

### Records set aside for next season

Records below have an issue_date after the end of migratory bird hunting for that state and where thus set aside for next year.

```{r reg_yr_check3, echo = FALSE}

future_data <-
  issue_assignments %>%
  filter(issue_id %in% c("copy", "postpone"))

if(nrow(future_data) > 0){
  future_summary <- 
    future_data %>% 
    group_by(dl_state, registration_yr, issue_id) %>% 
    summarize(n = n()) %>% 
    ungroup()
  
  DT::datatable(future_summary)
}else{
  message("No records to postpone.")
}

rm(future_data)
rm(issue_assignments)
rm(twoseasonstates)

```

## HuntY response checking

```{r hunty_check, echo = FALSE}
huntcheck <-
  final_data %>% 
  select(hunt_mig_birds, dl_state) %>% 
  group_by(hunt_mig_birds, dl_state) %>% 
  summarize(n = n()) %>% 
  ungroup() 

DT::datatable(huntcheck)

rm(huntcheck)
```

## PII checking

The following records are missing first name, last name, date of birth, address, state, and/or city AND zip. They are not included in the final output table.

```{r record_check, echo = FALSE, fig.align = "center"}
record_check <- 
  dl_data %>%
  # Filter out records if firstname, lastname, city of residence, state of
  # residence, or date of birth are missing -- records discarded because
  # these are needed to identify individuals
  # Discard additional records if they are missing elements of an address
  # and we have no way to resolve it from remaining information (i.e. state
  # from zip)
  filter(
    is.na(firstname)|
      is.na(lastname)|
      is.na(state)|
      is.na(birth_date)|
      is.na(address)|
      (is.na(city)&is.na(zip)))
  
if(nrow(record_check) > 0){
  missing_plot <-
    record_check %>%
    select(firstname, lastname, birth_date, state, address, city, zip) %>%
    # Add an ID per row
    mutate(hunter_id = row_number()) %>%
    # Pivot the field names to long format
    pivot_longer(firstname:zip, names_to = "field") %>%
    # Only keep hunters' fields with NA values
    filter(is.na(value)) %>%
    # Set NA to 1 for plotting
    mutate(value = 1) %>%
    # Make a heat map
    ggplot(aes(x = field, y = as.factor(hunter_id), fill = value)) +
    geom_tile() +
    labs(y = "Hunter ID", x = "Data Field") +
    theme_classic() +
    theme(legend.position = "none",
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

  print(missing_plot)}else{
  message("No records detected with missing PII.")
}
```

There are `r nrow(record_check)` total records with missing PII. Below is a summary of the number of records missing from each HIP file.

```{r pii_by_file, echo = FALSE}
pii_summary <- 
  record_check %>% 
  group_by(source_file) %>% 
  summarize(n = n()) %>% 
  ungroup() %>% 
  left_join(
    dl_data %>% 
      select(source_file) %>% 
      group_by(source_file) %>% 
      mutate(total_rows = n()) %>% 
      ungroup(),
    by = "source_file") %>% 
  mutate(prop = round(n/total_rows, digits = 2)) %>% 
  select(-total_rows) %>% 
  distinct() %>% 
  arrange(desc(prop)) 

DT::datatable(pii_summary)
rm(pii_summary)
rm(dl_data)
```

## Duplicates

### Before fixDuplicates (all 49 states)

```{r b_fd, echo = FALSE, fig.align = "center"}
findDuplicates(current_data)

rm(current_data)
```

### After fixDuplicates (all 49 states)

```{r a_fd, echo = FALSE, fig.align = "center"}
findDuplicates(fixed_data)

DT::datatable(findDuplicates(fixed_data, return = "table"))

rm(fixed_data)
```

## Strata

```{r stratacheck, echo = FALSE}
DT::datatable(
  strataCheck(final_data),
  extensions = "Buttons",
  options = 
    list(
      dom = "Bfrtip",
      buttons = c("csv", "excel", "pdf"))
  )
```

## Repeated values

### Repeated values across duck, goose, and snipe_coot bag codes

```{r h_validate, echo = FALSE}
DT::datatable(
  migbirdHIP::validate(final_data, type = "horizontal") %>% 
    mutate(prop_repeat = round(prop_repeat, digits = 2)))
```

### Repeated values within duck bag code

```{r v_validate, echo = FALSE}
DT::datatable(migbirdHIP::validate(final_data, type = "vertical"))
```

# Error Visualizations

## By field

### Before correction

```{r erpf, echo = FALSE, fig.align = "center"}
errorPlot_fields(proofed_data, year = params$year)
```

### After correction

```{r erpf_c, echo = FALSE, fig.align = "center", warning = FALSE}

# Get the order of the fields so that they match the plot above
x_order <-
  proofed_data %>%
  select(errors) %>%
  # Pull errors apart, delimited by hyphens
  separate(errors, into = as.character(c(1:25)), sep = "-") %>%
  # Transform errors into a single column
  pivot_longer(1:25, names_to = "name") %>%
  select(errors = value) %>%
  filter(!is.na(errors)) %>%
  group_by(errors) %>%
  # Count number of correct values
  summarize(count_errors = sum(!is.na(errors))) %>%
  ungroup() %>%
  # Calculate error proportion
  mutate(
    total = nrow(proofed_data),
    proportion = count_errors / nrow(proofed_data)) %>%
  arrange(proportion)

left_join(
  x_order %>% 
    mutate(order = row_number()) %>% 
    select(errors, order), 
  final_data %>%
    select(errors) %>%
    # Pull errors apart, delimited by hyphens
    separate(errors, into = as.character(c(1:25)), sep = "-") %>%
    # Transform errors into a single column
    pivot_longer(1:25, names_to = "name") %>%
    select(errors = value) %>%
    filter(!is.na(errors)) %>%
    group_by(errors) %>%
    # Count number of correct values
    summarize(count_errors = sum(!is.na(errors))) %>%
    ungroup(),
  by = "errors") %>%
  mutate(count_errors = ifelse(is.na(count_errors), 0, count_errors)) %>% 
  # Calculate error proportion
  mutate(
    total = nrow(final_data),
    proportion = count_errors / nrow(final_data)) %>%
  # Plot
  ggplot() +
  geom_bar(
    aes(x = reorder(errors, order), y = proportion),
    stat = "identity") +
  geom_text(
    aes(x = errors, y = proportion, label = count_errors, angle = 90),
    vjust = 0.2, hjust = -0.2) +
  labs(
    x = "Field",
    y = "Error proportion",
    title = "Error proportion per field") +
  scale_y_continuous(expand = expansion(mult = c(-0, 0.25))) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

```

## By state

### Before correction

```{r erps, echo = FALSE, fig.align = "center"}
errorPlot_states(proofed_data)
```

### After correction

```{r erps_c, echo = FALSE, fig.align = "center"}
errorPlot_states(final_data)

rm(final_data)
```

# Error Exploration

A closer look at common errors and issues within this download's HIP data.

## High error counts

Q: What were the most common fields with errors, and what values caused them?

Most common error fields...

```{r et, echo = FALSE}
et <- errorTable(proofed_data, loc = "none") %>% arrange(desc(error_count))

DT::datatable(et)
```

Values associated with error in `r et$error[1]`

```{r pe_1, echo = FALSE}

if(et$error[1] != "birth_date"){
  err1 <- 
    pullErrors(proofed_data, error = et$error[1], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err1 <- 
    pullErrors(proofed_data, error = et$error[1], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err1)
```

Values associated with error in `r et$error[2]`

```{r pe_2, echo = FALSE}

if(et$error[2] != "birth_date"){
  err2 <- 
    pullErrors(proofed_data, error = et$error[2], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err2 <- 
    pullErrors(proofed_data, error = et$error[2], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err2)
```

Values associated with error in `r et$error[3]`

```{r pe_3, echo = FALSE}

if(et$error[3] != "birth_date"){
  err3 <- 
    pullErrors(proofed_data, error = et$error[3], distinct = FALSE) %>% 
    as_tibble() %>% 
    mutate(value = stri_enc_toutf8(value, is_unknown_8bit = T, validate = T)) %>%
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
  }else{
  err3 <- 
    pullErrors(proofed_data, error = et$error[3], distinct = FALSE) %>% 
    as_tibble() %>%  
    mutate(value = str_extract(value, ".{4}$")) %>% 
    group_by(value) %>% 
    summarize(count = n()) %>% 
    ungroup() %>% 
    arrange(desc(count))
}

DT::datatable(err3)
```

## High error proportions

Q: What states and fields had a proportion of error that exceeded an acceptable threshold (before correction)?

States with more than 1% error

```{r rfs, echo = FALSE}
redFlags(proofed_data, type = "state", threshold = 0.1)
```

Fields with more than 1% error

```{r rff, echo = FALSE}
redFlags(proofed_data, type = "field", threshold = 0.1)
```
