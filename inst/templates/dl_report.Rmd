---
title: "Harvest Information Program Download Cycle Report"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    theme: cerulean
params:
  comp_path:
    value: x
  dl:
    value: x
  year:
    value: x
---

```{r libs, include = FALSE}
library(tidyverse)
library(DT)
library(shiny)
```

```{r import, include = FALSE}

acceptable_residences <-
        c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", "ID",
          "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", "MI", "MN",
          "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC", "ND",
          "OH", "OK", "OR","PA", "RI", "SC", "SD", "TN", "TX", "UT", "VT",
          "VA", "WA", "WV", "WI", "WY", "DC", "HI", "AS", "GU", "MP", "PR", 
          "VI", "UM", "AA", "AE","AP")

dl_data <- read_hip(params$comp_path) %>% mutate(dl_cycle = params$dl)

cleaned_data <- clean(dl_data)

fixed_data <- fixDuplicates(cleaned_data)

proofed_data <- proof(fixed_data, year = params$year)

corrected_data <- correct(proofed_data, year = params$year, data = "bag")

```

# Introduction

This is a report of download cycle `r proofed_data %>% select(dl_cycle) %>% distinct %>% pull`. This cycle, `r sumLines(params$comp_path)` lines of data (`r nrow(fixed_data)` unique records) were submitted in `r length(list.files(params$comp_path) %>% as_tibble() %>% transmute(filepath = as.character(value)) %>% mutate(filepath = str_replace(filepath, "TXT", "txt")) %>% filter(str_detect(filepath, "(?<=\\.)txt$")) %>% pull)` files from `r proofed_data %>% select(dl_state) %>% distinct %>% nrow()` states.

Below is a table summarizing the total of number of records per download state.

```{r sum_per_state, echo = FALSE, message = FALSE}

DT::datatable(cleaned_data %>% 
                select(dl_state) %>% 
                group_by(dl_state) %>% 
                summarize(sum = n()) %>% 
                ungroup())

```

# Data Checking

## Hunt migratory birds response checking

Below is a summary of all values in the hunt_mig_birds field.

```{r huncheck, echo = FALSE}
huntcheck <-
  cleaned_data %>% 
  select(hunt_mig_birds) %>% 
  group_by(hunt_mig_birds) %>% 
  summarize(n = n()) %>% 
  ungroup() 

DT::datatable(huntcheck)

rm(huntcheck)
```

## PII checking

The following records are missing first name, last name, date of birth, address, city, and/or state of residence. They were not included in the final output table.

```{r record_check, echo = FALSE}
record_check <- 
  dl_data %>%
  rename(
    title = X1,
    firstname = X2,
    middle = X3,
    lastname = X4,
    suffix = X5,
    address = X6,
    city = X7,
    state = X8,
    zip = X9,
    birth_date = X10,
    # Edited X11 to specific .data$X11 to avoid error:
    # "Found an obsolete/platform-specific call in: 'tidy'"
    # "Found the platform-specific device: 'X11'"
    issue_date = X11,
    hunt_mig_birds = X12,
    ducks_bag = X13,
    geese_bag = X14,
    dove_bag = X15,
    woodcock_bag = X16,
    coots_snipe = X17,
    rails_gallinules = X18,
    cranes = X19,
    band_tailed_pigeon = X20,
    brant = X21,
    seaducks = X22,
    registration_yr = X23,
    email = X24) %>%
  # Filter out records if firstname, lastname, city of residence, state of
  # residence, or date of birth are missing -- records discarded because
  # these are needed to identify individuals
  # Discard additional records if they are missing elements of an address
  # and we have no way to resolve it from remaining information (i.e. state
  # from zip)
  filter(
    is.na(firstname)|
      is.na(lastname)|
      is.na(state)|
      is.na(birth_date)|
      is.na(address)|
      (is.na(city)&is.na(zip)))
  

DT::datatable(record_check %>% select(title:birth_date))
```

Summary of missing PII by .txt file.

```{r pii_by_file}
pii_summary <- 
  record_check %>% 
  group_by(source_file) %>% 
  summarize(n = n()) %>% 
  ungroup()

DT::datatable(pii_summary)
rm(pii_summary)
```

Plot of missing PII.

```{r pii_plot, echo = FALSE}

if(nrow(record_check) > 0){
  missing_plot <-
    record_check %>%
    select(firstname, lastname, city, state, birth_date) %>%
    # Add an ID per row
    mutate(hunter_id = row_number()) %>%
    # Pivot the field names to long format
    pivot_longer(firstname:birth_date, names_to = "field") %>%
    # Only keep hunters' fields with NA values
    filter(is.na(value)) %>%
    # Set NA to 1 for plotting
    mutate(value = 1) %>%
    # Make a heat map
    ggplot(aes(x = field, y = as.factor(hunter_id), fill = value)) +
    geom_tile() +
    labs(y = "Hunter ID", x = "Data Field") +
    theme_classic() +
    theme(legend.position = "none",
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank())

  print(missing_plot)}else{
  message(
    paste0("No records detected with missing first name, last name, city",
           " state, or date of birth.")
  )
}

rm(record_check)
rm(dl_data)
```

## State of residence checking

Below are all states of residence reported in this download cycle. USA (state, district, and territory) and Canada (province and territory) abbreviations are parsed and flagged accordingly in the "country" column. All other state values are marked as "other".

```{r state_check, echo = FALSE}
rm(record_check)

state_check <-
  cleaned_data %>% 
  select(state) %>% 
  group_by(state) %>% 
  summarize(n_records = n()) %>% 
  ungroup() %>% 
  mutate(
    country = 
      case_when(
        state %in% c("AB", "BC", "MB", "NB", "NL", "NT", "NS", "NU", "ON", "PE", "QC", "SK", "YT") ~ "Canada",
        state %in% acceptable_residences ~ "USA", 
        TRUE ~ "Other")) %>%
  arrange(country)

DT::datatable(state_check)
```

# Zip code accuracy checking 

Check to see which records, if any, have reported zip codes that do not belong to the state of residence.

```{r zip, echo = FALSE}
zip_check <-
  fixed_data %>% 
  mutate(zipPrefix = str_extract(zip, "^[0-9]{3}")) %>%
  left_join(
    zip_code_ref %>%
      select(zipPrefix, zipState = state),
    by = "zipPrefix") %>%
  filter(state != zipState) %>% 
  select(record_key, zip, state, zipState)
      
DT::datatable(zip_check)
rm(zip_check)
```

## Duplicates

### Before fixDuplicates (all 49 states)

```{r b_fd, echo = FALSE}
rm(state_check)

findDuplicates(cleaned_data)

DT::datatable(findDuplicates(cleaned_data, return = "table"))
```

### After fixDuplicates (all 49 states)

```{r a_fd, echo = FALSE}
findDuplicates(fixed_data)

DT::datatable(findDuplicates(fixed_data, return = "table"))
```

## Strata

```{r stratacheck, echo = FALSE}
DT::datatable(strataCheck(fixed_data))
```

## Repeated values

### Horizontal

```{r h_validate, echo = FALSE}
DT::datatable(migbirdHarvestData::validate(fixed_data, type = "horizontal"))
```

### Vertical

```{r v_validate, echo = FALSE}
DT::datatable(migbirdHarvestData::validate(fixed_data, type = "vertical"))
```

```{r data_sweep, include = FALSE}

# Remove data objects to improve memory use
rm(cleaned_data)
rm(fixed_data)
```

# Error Visualizations

## By field

### Before correction

```{r erpf, echo = FALSE}
errorPlot_fields(proofed_data, year = params$year)
```

### After correction

```{r erpf_c, echo = FALSE}
errorPlot_fields(corrected_data, year = params$year)
```

## By state

### Before correction

```{r erps, echo = FALSE}
errorPlot_states(proofed_data)
```

### After correction

```{r erps_c, echo = FALSE}
errorPlot_states(corrected_data)
```

# Error Exploration

Let's take a closer look at common errors and issues within this download's HIP data.

## High error counts

Q: What were the most common fields with errors, and what values caused them?

Most common error fields...

```{r et, echo = FALSE}
et <- errorTable(proofed_data, loc = "none") %>% arrange(desc(error_count))

DT::datatable(et)
```

Values associated with error in `r et$error[1]`

```{r pe_1, echo = FALSE}
err1 <- 
  pullErrors(proofed_data, error = et$error[1]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err1)
```

Values associated with error in `r et$error[2]`

```{r pe_2, echo = FALSE}
err2 <- 
  pullErrors(proofed_data, error = et$error[2]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err2)
```

Values associated with error in `r et$error[3]`

```{r pe_3, echo = FALSE}
err3 <- 
  pullErrors(proofed_data, error = et$error[3]) %>% 
  as_tibble() %>% 
  group_by(value) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  arrange(desc(count))

DT::datatable(err3)
```

## High error proportions

Q: What states and fields had a proportion of error that exceeded an acceptable threshold (before correction)?

States with more than 1% error

```{r rfs, echo = FALSE}
redFlags(proofed_data, type = "state", threshold = 0.1)
```

Fields with more than 1% error

```{r rff, echo = FALSE}
redFlags(proofed_data, type = "field", threshold = 0.1)
```
