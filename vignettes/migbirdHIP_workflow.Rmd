---
title: "The migbirdHIP Workflow"
package: migbirdHIP
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The migbirdHIP Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Table of Contents

- [Introduction](#introduction)
    - [Installation](#installation)
    - [Functions overview](#functions-overview)
- [Part A: Data Import and Cleaning](#part-a-data-import-and-cleaning)
    - [read_hip](#read_hip)
    - [renameFiles](#renamefiles)
    - [shiftFix](#shiftFix)
    - [clean](#clean)
    - [issueCheck](#issueCheck)
    - [findDuplicates](#findduplicates)
    - [fixDuplicates](#fixduplicates)
    - [strataCheck](#stratacheck)
    - [validate](#validate)
    - [investigate](#investigate)
- [Part B: Data Proofing and Correction](#part-b-data-proofing-and-correction)
    - [proof](#proof)
    - [correct](#correct)
    - [pullErrors](#pullerrors)
    - [manualFix](#manualfix)
    - [write_hip](#write_hip)
    - [writeReport](#writereport)
    - [writeShiny](#writeshiny)
- [Part C: Data Visualization and Tabulation](#part-c-data-visualization-and-tabulation)
    - Visualization
        - [outOfStateHunters](#outofstatehunters)
        - [youthHunters](#youthhunters)
        - [errorPlot_fields](#errorplot_fields)
        - [errorPlot_states](#errorplot_states)
        - [errorPlot_dl](#errorplot_dl)
    - Tabulation
        - [errorTable](#errortable)
        - [redFlags](#redflags)
- [Troubleshooting](#troubleshooting)
    - [Common read_hip warnings](#common-read_hip-warnings)
    - [Memory problems](#memory-problems)
    - [Other](#other)

## Introduction

The *migbirdHIP* package was created for the U.S. Fish and Wildlife Service (USFWS) to wrangle, tidy, and visualize Harvest Information Program (HIP) data.

HIP data have been used since 1999 to make important management decisions for migratory game birds in the United States. Raw hunting activity data are processed in this package. To read more about HIP, visit: [https://www.fws.gov/harvestsurvey/](https://www.fws.gov/harvestsurvey/)

### Installation

The package can be installed from the USFWS GitHub repository using:

```r
devtools::install_github("USFWS/migbirdHIP", quiet = T, upgrade = F, , build_vignettes = T)
```

### Functions overview

The flowchart below is a visual guide to the order in which functions are used. Some functions are only used situationally and some issues with the data cannot be solved using a function at all. The general process of handling HIP data is demonstrated here; every function in the *migbirdHIP* package is included.

<img src="image/migbirdHIP_flowchart.svg" title="Overview of migbirdHIP functions in a flowchart format." alt="Overview of migbirdHIP functions in a flowchart format." width="100%" style="display: block; margin: auto;" />

## Part A: Data Import and Cleaning

### read_hip

The first step is to import fixed-width .txt files containing HIP data. Files must adhere to a 10-digit naming convention in order to successfully import data using the `read_hip` function; if files were submitted with the old 5-digit format, run [renameFiles](#renamefiles) first.

The `read_hip` function allows data to be read in for all states (e.g. `state = NA`, the default), for just a specific state (e.g. `state = "DE"`), a specific download (e.g. `season = FALSE`, the default) or data over an entire season (e.g. `season = TRUE`). Use `unique = TRUE` to read in a frame without exact duplicates, or `unique = FALSE` for all records. This function also:

* Returns a message if one or more files are blank in the directory
* Return a message by download state for records with blank or NA values in firstname, lastname, state, or birth date
* Guesses encodings of .txt files and prints a table of any that are not UTF-8
* Checks download state abbreviations in the .txt file names
* Trims whitespace on all values
* Converts "N/A" strings to NA
* Creates a dl_state, dl_date, dl_cycle, and source_file column from each .txt filename
* Creates a dl_key column by grouping data by dl_state and dl_date
* Creates a record_key column (unique identifier for each row, used later by [shiftFix](#shiftFix))

We will use the default settings to read in all of the states from download 1301.


```r
library(migbirdHIP)

DL1301 <- read_hip("C:/HIP/DL1301")
```

```
## # A tibble: 4 × 3
##   filepath                     encoding   confidence
##   <chr>                        <chr>           <dbl>
## 1 C:/HIP/DL1301/GA20211229.txt ISO-8859-1       0.23
## 2 C:/HIP/DL1301/MO20211229.txt ISO-8859-1       0.26
## 3 C:/HIP/DL1301/NE20211217.txt ISO-8859-1       0.32
## 4 C:/HIP/DL1301/NE20211217.txt ISO-8859-2       0.21
## # A tibble: 13 × 3
##    dl_state mean_prop     n
##    <chr>        <dbl> <int>
##  1 LA           1         1
##  2 WV           0.75      1
##  3 IN           0.667     3
##  4 AL           0.25      1
##  5 FL           0.25      5
##  6 GA           0.25     11
##  7 IA           0.25      4
##  8 ID           0.25      1
##  9 ME           0.25      1
## 10 OK           0.25     25
## 11 OR           0.25      1
## 12 TN           0.25      9
## 13 VA           0.25      7
```

Did you get a warning or three? Read an explanation of common `read_hip` warnings, [below](#common-read_hip-warnings).

### renameFiles

The `renameFiles` function was incorporated into this package for special cases. Some states submit .txt  files using a 5-digit file name format, containing 2 letters for the state abbreviation followed by a 3-digit Julian date (representing the date the file was uploaded). To convert these 5-digit filenames to the standard 10-digit format (a requirement to read data properly with [read_hip](#read_hip)), supply the `renameFiles` with the directory containing HIP data. File names will be automatically overwritten with the YYYYMMDD format date corresponding to the submitted Julian date. This function also converts lowercase state abbreviations to uppercase.


```r
renameFiles(path = "C:/HIP/DL1301")
```

### shiftFix

The `shiftFix` function moves row values by a designated number of characters across a designated span of columns. It takes parameters `x`, `record_id`, `first_col`, `last_col`, and `n_shift`. For example, if we wanted to modify the 117th row (with row id = "row_117") in a dataframe called "ducks" from column "wing" to column "tail", to shift the data 2 characters to the left, we would run:

`shiftFix(x = ducks, record_id = "row_117", first_col = "wing", last_col = "tail", n_shift = 2)`

For HIP processing, this function is used in conjunction with other R code to achieve a final dataframe.


```r
library(tidyverse)

# Snooping
snoop <-
  DL1301 %>%
  filter(
    !str_detect(birth_date, "^[0-9]{2}\\/[0-9]{2}\\/[0-9]{4}$")) %>%
  mutate(n_shift = stringr::str_length(str_extract(issue_date, "^[0-9]+(?=\\/)")) - 2) %>%
  relocate(record_key, .before = "title") %>%
  relocate(source_file, .before = "record_key") %>%
  select(record_key, n_shift) %>%
  print()
```

```
## # A tibble: 1 × 2
##   record_key   n_shift
##   <chr>          <dbl>
## 1 record_32904       1
```

```r
# Correct frame shift for x number of records
unshifted <-
  map_dfr(
    1:length(snoop$record_key),
    ~shiftFix(
      # Fix the raw data file
      DL1301,
      # For x record id
      snoop$record_key[.x],
      # Shift from state col to email col
      "state",
      "email",
      # Shift n number of characters
      snoop$n_shift[.x])) %>%
  # Delete the 0s from end of zip
  mutate(zip = str_remove(zip, "0$")) %>%
  # Add 0s to the beginning of birth_date
  mutate(
    birth_date =
      ifelse(
        str_detect(birth_date, "^[0-9]{1}\\/"),
        paste0("0", birth_date),
        birth_date))

DL1301_unshifted <-
  DL1301 %>%
  filter(!record_key %in% unshifted$record_key) %>%
  bind_rows(unshifted)
```

### clean

After data are read and unshifted, we `clean`:


```r
DL1301_clean <- clean(DL1301_unshifted)
```

This function does simple data cleaning. Importantly, records are discarded if first name, last name, birth date, state of residence, address AND email, OR city AND zip AND email are missing.

Other quick fixes include:

* Converts names to uppercase
* Moves suffixes from first or last name columns to the appropriate suffix column (including any value from I to XX or 1ST to 20TH, except for XVIII)
* If any value other than a letter is in the middle initial column, it's set to NA
* Zip code correction
    * Removes ending hyphen from zip codes with only 5 digits
    * Inserts a hyphen in continuous 9 digit zip code values
    * Inserts a hyphen in 9 digit zip codes with a middle space
    * Deletes trailing -0000 and -____ from zip codes
* Address cleaning
    * Deletes leading "." in addresses (a spillover character from suffix)
    * Attempt at PO Box standardization, by changing "P.O.BOX" to "PO BOX" and "P.O. BOX" to "PO BOX"
* Trims whitespace on all values (again)

### issueCheck

Sometimes we receive HIP records that should be processed in a future season. We also sometiems receive records that should be processed in both this season and a future one, since some states have license years that encompass two seasons. The `issueCheck` function evaluates issue_date and registration_yr for two-season states (ME, MA, ID, CT, WV, VT, NH, IA, ND, SD, and TN) as well as a 365-day state (MS). It sets aside future records and past records in separate .csv files to be evaluated later. Only the current registrations are returned.

For ME, MA, ID, CT, WV, VT, NH, IA, ND, SD, and TN:

* If a record's issue_date is between issue_start and last day of hunting season, AND registration_yr is for next season, (1) COPY the record for next year and (2) CHANGE registration_yr for this year (subtract 1) so it's includable in the sample.
* If a record's issue_date is after the end of hunting season, SET IT ASIDE for next year.
* If a record's registration_yr is yr-1, SET IT ASIDE as past data.

For MS:

* If a record's issue_date is between the first day of the hunting season and the last day of the hunting season in Mississippi, keep a copy for this year (with registration_yr as the current year) and copy one for next year (registration_yr + 1).

For all states:

* If a record's registration_yr is in the future, SET IT ASIDE for next year.



```r
DL1301_current <- issueCheck(DL1301_clean, year = 2021, plot = F, write = F)
```

```
## * 709 records have been modified to have registration_yr - 1. They have been copied and saved for next season in the future data .csv with their original registration_yr.
```

```
## * No records need to be postponed for next year.
```

```
## * No past records detected.
```

```
## # A tibble: 4 × 4
##   reg_yr_eval issue_eval       decision sum_n
##   <chr>       <chr>            <chr>    <int>
## 1 copy        two season state copy       709
## 2 nochange    past             bad      33225
## 3 nochange    two season state nochange  8452
## 4 postpone    past             bad       6615
```

To export a table of records to process in a future season and to set aside records from past seasons to include in the download report, specify the outpaths where the .csv files should be written and specify `write = TRUE`.


```r
DL1301_current <- issueCheck(DL1301_clean, year = 2021, future_outpath = "C:/HIP/future_data/", past_outpath = "C:/HIP/past_data/", plot = F, write = T)
```

To print a plot of bad records in which the registration_yr and issue_date do not agree, use `plot = T`.


```r
DL1301_current <- issueCheck(DL1301_clean, year = 2021, plot = T, write = F)
```

### findDuplicates

The `findDuplicates` function finds hunters that have more than one registration. Records are grouped by first name, last name, state, birth date, registration year, and download state to identify unique hunters. If the same hunter has 2 or more registrations, the fields that are not identical are counted and summarized. A plot is returned by default, but the type of output can be specified using `return = "plot"` for plot, or `return = "table"` for table and summary message.


```r
findDuplicates(DL1301_current)
```

<img src="figure/findDuplicates-1.png" title="Figure 1. Plot of types of duplicates." alt="Figure 1. Plot of types of duplicates." width="500" style="display: block; margin: auto;" />


```r
findDuplicates(DL1301_current, return = "table")
```

```
## # A tibble: 15 × 2
##    dupl                                         count
##    <chr>                                        <int>
##  1 address                                          2
##  2 address-city                                     1
##  3 address-email                                    2
##  4 address-zip-email                                1
##  5 address-zip-issue_date                           1
##  6 bag                                            485
##  7 email                                            2
##  8 hunt_mig_birds                                   1
##  9 issue_date                                      25
## 10 issue_date-dl_date                               1
## 11 issue_date-email                                 1
## 12 issue_date-hunt_mig_birds-dl_date                3
## 13 middle                                           5
## 14 middle-address-city-zip-hunt_mig_birds-email     1
## 15 suffix-issue_date-email                          1
```

### fixDuplicates

We sometimes receive multiple HIP records per person which must be resolved by `fixDuplicates`. Only 1 HIP record per hunter can be kept. To decide which record to keep from a group, we follow a series of logic.

Records are kept when they meet the below criteria (in order of importance):

1. The record in the group has the most recent issue date.
2. Records do not contain all 1s or all 0s in bag columns.
3. For duplicates from sea duck and brant states (AK, CA, CT, DE, MA, MD, NC, NH, NJ, NY, RI, VA), keep records with a 2 in seaduck or brant.
4. For duplicates from seaduck-only state (ME), keep records with a 2 in seaduck.
5. If records are tied, one is chosen randomly.

A new field called "record_type" is added to the data after the above deduplicating process. Every HIP record is labeled "HIP". Permit states WA, OR, CO, and SD send HIP and permit records separately, which are labeled "HIP" and "PMT" respectively.

Note: This function replaces "." values with NA in non-permit species columns for WA, OR, CO, and SD records.



```r
DL1301_fixed <- fixDuplicates(DL1301_current)
```

### strataCheck

Running `strataCheck` ensures species "bag" values are in order. This function searches for values in species group columns that are not typical or expected by the FWS. If a value outside of the normal range is detected, an output tibble is created. Each row in the output contains the state, species, unusual stratum value, and a list of the normal values we would expect.

If a value for a species group is given in the HIP data that doesn't match anything in our records, the species reported in the output will have NA values in the "normal_strata" column. These species are not hunted in the reported states.


```r
strataCheck(DL1301_fixed)
```

```
## # A tibble: 38 × 4
##    dl_state spp          state_strata normal_strata
##    <chr>    <chr>        <chr>        <chr>        
##  1 AL       woodcock_bag 3            1, 2, 4, 5   
##  2 FL       dove_bag     0            1, 2, 3, 5   
##  3 IA       dove_bag     0            1, 2, 3, 5   
##  4 OR       dove_bag     0            1, 2, 3, 5   
##  5 TN       dove_bag     0            1, 2, 3, 5   
##  6 TN       woodcock_bag 0            1, 2, 3, 5   
##  7 IA       ducks_bag    0            1, 2, 3, 4   
##  8 IA       geese_bag    0            1, 2, 3, 4   
##  9 OR       ducks_bag    0            1, 2, 3, 4   
## 10 OR       geese_bag    0            1, 2, 3, 4   
## # … with 28 more rows
```

### validate

The `validate` function looks for repeated values in two dimensions, both horizontally and vertically.

<b>Horizontally.</b> The horizontal check for repetition looks across records and finds any rows with same value in each species group column. Details in the output tibble include: the repeated value (h_value), number of records with repeats (h_rep), total number of records (h_total), and proportion of repeated values per file (prop_repeat). The default version of this function (`all = FALSE`) only checks ducks, geese, and coots_snipe bags. If the parameter is set to `all = TRUE`, every species group will be checked.


```r
validate(DL1301_fixed, type = "horizontal")
```

```
## # A tibble: 49 × 5
##    source_file    h_value h_rep h_total prop_repeat
##    <chr>          <chr>   <int>   <int>       <dbl>
##  1 IA20211215.txt 0        2841    3175       0.895
##  2 AL20211229.txt 1        4223    4790       0.882
##  3 WI20211229.txt 1         273     323       0.845
##  4 MO20211229.txt 1        2697    3604       0.748
##  5 ME20211229.txt 1         112     151       0.742
##  6 NM20211229.txt 1         208     295       0.705
##  7 ID20211229.txt 1        1762    2588       0.681
##  8 ND20211215.txt 1         130     204       0.637
##  9 CA20211229.txt 1        2003    3211       0.624
## 10 IN20211229.txt 1         416     690       0.603
## # … with 39 more rows
```

<b>Vertically.</b> The vertical check searches within each column for repetition. Any species group column with the same value in all rows will be detected. The default version of this function (`all = FALSE`) only checks duck bags. If the parameter is set to `all = TRUE`, every species group will be checked.

The two time period options to assess vertical repetition are `period = "dl_date"` (used automatically)...




```r
validate(DL1301_fixed, type = "vertical")
```

```
## # A tibble: 1 × 4
##   dl_state dl_date  species_grp v_repeated
##   <chr>    <chr>    <chr>            <int>
## 1 AK       20211228 ducks_bag           65
```

... and `period = "dl_cycle"`.


```r
validate(DL1301_fixed, type = "vertical", period = "dl_cycle")
```

```
## # A tibble: 1 × 4
##   dl_state dl_cycle species_grp v_repeated
##   <chr>    <chr>    <chr>            <int>
## 1 AK       1301     ducks_bag           65
```

It is not possible to include as much detail in the vertical output as in the horizontal output without being specific about which state, species, and time scale you wish to assess. Vertical repetition returned in the output from this function can be looked at more closely using `investigate`.

If there are no repetitions, a positive message will be returned.

### investigate

Did the vertical output from the `validate` function return repeated values? Are some of those values a high number that are repeated and need to be looked at more closely? The `investigate` function allows you to see what value was vertically repeated for a species. Parameters required are download state, type of download time period, value of the download date or download cycle, and species — all of this information is provided in the vertical `validate` output.


```r
investigate(
  DL1301_fixed,
  loc = "AK",
  period_type = "dl_date",
  period = "20211228",
  species = "ducks_bag")
```

```
## # A tibble: 1 × 2
##   ducks_bag source_file   
##   <chr>     <chr>         
## 1 3         AK20211228.txt
```

## Part B: Data Proofing and Correction

### proof

After data are cleaned and checked for any important issues that would require manual attention, we `proof`:


```r
DL1301_proofed <- proof(DL1301_fixed, year = 2021)
```

```
## # A tibble: 3 × 3
##   source_file        n  prop
##   <chr>          <int> <dbl>
## 1 AL20211229.txt  4790     1
## 2 LA20211217.txt   608     1
## 3 LA20211220.txt  1192     1
```

Data that are considered irregular are flagged in a new column called "errors". No actual corrections take place in this step; all data remain identical except for the new "errors" column. For each field, values are compared to standard expected formats and if they do not conform, the field name is pasted as a string in the "errors" column. Each row can have from zero errors (NA) to all column names listed. Multiple flags are hyphen delimited.

The year of the Harvest Information Program must be supplied as a parameter. This aids in checking dates when licenses were issued, as one example.

### correct

After the download data are proofed, the next step is to fix the data to the best of our ability. Data can be corrected by running the `correct` function on the proofed tibble. The year of the Harvest Information Program must be supplied as a parameter. Since the "errors" column is re-created using `correct`, supplying the year is necessary for the same reasons it is required by `proof`.


```r
DL1301_corrected <- correct(DL1301_proofed, year = 2021)
```

```
## # A tibble: 3 × 3
##   source_file        n  prop
##   <chr>          <int> <dbl>
## 1 AL20211229.txt  4790     1
## 2 LA20211217.txt   608     1
## 3 LA20211220.txt  1192     1
## # A tibble: 129 × 4
##    record_key  zip        state zipState
##    <chr>       <chr>      <chr> <chr>   
##  1 record_892  71646      AZ    AR      
##  2 record_1214 53473      AL    WI      
##  3 record_1334 30152-4158 AL    GA      
##  4 record_1706 25652      AL    WV      
##  5 record_2217 35959      GA    AL      
##  6 record_3432 32567      AL    FL      
##  7 record_3448 30456      AL    GA      
##  8 record_3825 36005      FL    AL      
##  9 record_4202 20097      NC    DC      
## 10 record_4706 29744      NC    SC      
## # … with 119 more rows
```

The following changes are made by the `correct` function:

* *Title* is changed to NA if it does not equal 1 or 2
* *First name* is not changed, but remains flagged as an error if it breaks a following rule:
    * Not > 1 letter
    * Contains a first initial and middle name
    * Contains a first name and middle initial
    * Contains non-alpha characters other than space or hyphen
    * No full names (detected with 2+ spaces)
    * Is not "BLANK", "INAUDIBLE", "TEST", "USER", or "RESIDENT"
* *Middle initial* is not changed, but remains flagged if it is not exactly 1 letter
* *Last name* is not changed, but remains flagged as an error if it breaks a following rule:
    * Not > 1 letter
    * Contains a non-alpha character other than space, period, hyphen, or apostrophe
    * No full names (Detected with 2+ spaces)
    * Is not "INAUDIBLE"
* *Suffix* is changed to NA if it is not equal to:
    * JR or SR
    * A value from I to VII in Roman numerals
    * An value from 1ST to 9TH
* *Address* is not changed, but remains flagged if it contains a |, tab, or non-UTF8 character
* *City* is not changed, but remains flagged if it contains any non-alpha character
* *State* is not changed, but remains flagged if it is not contained in the following list of abbreviations for US and Canada states, provinces, and territories:
    * AL, AK, AZ, AR, CA, CO, CT, DE, DC, FL, GA, HI, ID, IL, IN, IA, KS, KY, LA, ME, MD, MA, MI, MN, MS, MO, MT, NE, NV, NH, NJ, NM, NY, NC, ND, OH, OK, OR, PA, RI, SC, SD, TN, TX, UT, VT, VA, WA, WV, WI, WY, AS, GU, MP, PR, VI, UM, FM, MH, PW, AA, AE, AP, CM, CZ, NB, PI, TT, ON, QC, NS, NB, MB, BC, PE, SK, AB, NL
* *Zip* is not changed, but is flagged if:
    * If the hunter's address doesn't have a zip that should be in their reported state of residence (checked against a master list of USA postal codes), it's flagged
    * Foreign zip codes are flagged
    * Zip codes that do not match a 5-digit or 9-digit hyphenated format are flagged
* *Birth date* is not changed, but remains flagged if the birth year was > 100 or < 16 years ago
* *Issue date* is not changed, but remains flagged if it is not equal to or +/- 1 year from the HIP data collection year
* *Hunt migratory birds* is not changed, and remains flagged if it is not equal to 1 or 2
* *Bag values* remain unchanged
* *Registration year* is not changed, but remains flagged if it is not equal to or +/- 1 year from the HIP data collection year
* *Email* is corrected by:
    * Removing spaces, commas, and/or forward slash symbols
    * Changing to lowercase
    * Replacing multiple @ symbols with a single @
    * Adding periods and three-letter endings to common domains, including:
        * gmail -> gmail.com
        * yahoo -> yahoo.com
        * aol -> aol.com
        * comcast -> comcast.net
        * verizon -> verizon.net
        * cox -> cox.net
        * outlook -> outlook.com
        * hotmail -> hotmail.com
    * Replace .ccom with .com
    * Add missing periods before net, com, edu, and gov
    * Change email to NA if:
        * There is no @ symbol in the email string
        * If the email is invalid (i.e. none<!-- breaklink -->@none, noemail, n/a)
    * Any email that wasn't corrected and doesn't fit the standardized email regex remains flagged

All functions in [Part C](#part-c-data-visualization-and-tabulation) will run on the corrected tibble, `DL1301_corrected`, just as they worked on the example tibble `DL1301_proofed`. Errors can be compared between the proofed stage and corrected stage to get a better idea of which errors were serious (i.e. difficult to correct automatically) and determine how serious errors can be prevented in the future.

### pullErrors

The `pullErrors` function can be used to view all of the actual values that were flagged as errors in a particular field. In this example, we find that the "suffix" field contains several values that are not accepted.


```r
pullErrors(DL1301_proofed, error = "suffix")
```

```
##  [1] "MD"  "ESQ" "MAL" "MR"  "W"   "CJS" "CME" "M"   "SMI" "I�M" "MO"  "MS"  "MRS" "-"
```

Running `pullErrors` on a field that has no errors will return a message.


```r
pullErrors(DL1301_proofed, error = "dove_bag")
```

```
## Success! All values are correct.
```

### manualFix

The automated `correct` function cannot always catch and fix every error. To finish the job, `manualFix` function replaces specified inaccurate values with the values you want. It is not recommended that this function only be used after correcting the data; it's best used on a case-by-case basis. If problems are only identified after `proof`, you can run `manualFix` on the cleaned data and re-run `proof`. This function is highly flexible and recommended to be used as needed.

In the below example, a "GS" value in the state field is corrected to "GA".


```r
manualFix(DL1301_corrected, field = "state", error_value = "GS", correct_value = "GA")
```

### write_hip

After the data have been processed with `correct`, the table is ready to be written for the database. Use `write_hip` to do final processing to the table, which includes adding in FWS strata and setting NAs to blank strings. If `split = FALSE`, the final table will be saved as a single .csv to your specified path. If `split = TRUE` (default), one .csv file per each input .txt source file will be written to the specified directory.


```r
write_hip(DL1301_corrected, path = "C:/HIP/processed_data/")
```

### writeReport

The `writeReport` function can be used to automatically generate an R markdown document with figures, tables, and summary statistics. This can be done at the end of a download cycle (using `type = "dl_report"`) or the entire HIP season (with `type = "season_report"`).  Writing a total season report is a memory intensive process, so for this option, we recommend [increasing your memory](#memory-problems) allocated to R.


```r
# Windows only
memory.limit(size = 55000)

writeReport(
  path = "C:/HIP/DL1301",
  type = "dl_report",
  corrected_path = "C:/HIP/corrected_data",
  future_path = "C:/HIP/future_data",
  past_path = "C:/HIP/past_data",
  yr = 2019,
  dl = "1301",
  dir = "C:/HIP/dl_reports",
  file = "DL1301_report")
```

## Part C: Data Visualization and Tabulation

### outOfStateHunters

The `outOfStateHunters` function plots and tabulates how many hunters registered in a download state that does not match the state, province, or territory of their address. This function plots proportion of out-of-staters with counts as bar labels. The tibble contains counts and proportions by state.


```r
outOfStateHunters(DL1301_proofed)
```

<img src="figure/outofstate-1.png" title="Figure 6. Plot of proportions of out-of-state hunters." alt="Figure 6. Plot of proportions of out-of-state hunters." width="500" style="display: block; margin: auto;" />

### youthHunters

The `youthHunters` function returns a table and plot of the number of hunters with birth dates < 16 years from the year of HIP data collection. These data are interesting to explore because hunters younger than 16 years of age are not required to have a migratory bird hunting license in the United States.


```r
youthHunters(DL1301_proofed, year = 2021)
```

<img src="figure/youth-1.png" title="Figure 7. Plot of proportions of youth hunters." alt="Figure 7. Plot of proportions of youth hunters." width="500" style="display: block; margin: auto;" />

### errorPlot_fields

The `errorPlot_fields` function can be run on all states...


```r
errorPlot_fields(DL1301_proofed, loc = "all", year = 2021)
```

<img src="figure/errorfieldsplotall-1.png" title="Figure 2. Plot of all location's errors by field name." alt="Figure 2. Plot of all location's errors by field name." width="500" style="display: block; margin: auto;" />

... or it can be limited to just one.


```r
errorPlot_fields(DL1301_proofed, loc = "LA", year = 2021)
```

<img src="figure/errorfieldsplotsc-1.png" title="Figure 3. Plot of Louisiana's errors by field name." alt="Figure 3. Plot of Louisiana's errors by field name." width="500" style="display: block; margin: auto;" />

The `youth` parameter can be set to TRUE for `errorPlot_fields` to view the proportion of "errors" created by youth hunters. Youth hunters are not included in the error plot if `youth = FALSE` (set as default).


```r
errorPlot_fields(DL1301_proofed, year = 2021, youth = TRUE)
```

<img src="figure/errorfieldsplotyouth-1.png" title="Figure 4. Plot of all location's errors by field name, with stacked colors to indicate if there are youth hunters or Canadian zip codes in the data, two common causes of error." alt="Figure 4. Plot of all location's errors by field name, with stacked colors to indicate if there are youth hunters or Canadian zip codes in the data, two common causes of error." width="500" style="display: block; margin: auto;" />

It is possible to add any `ggplot2` components to these plots. For season total data specifically, the plot can be facet_wrapped using either dl_cycle or dl_date. The example below demonstrates how this package's functions can interact with the tidyverse and shows an example of an `errorPlot_fields` facet_wrap (using a subset of 4 download cycles)


```r
errorPlot_fields(
  hipdata2020 %>%
    filter(str_detect(dl_cycle, "0800|0901|0902|1001")),
    year = 2021) +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1),
    legend.position = "bottom") +
  facet_wrap(~dl_cycle, ncol = 2)
```

### errorPlot_states

The `errorPlot_states` function plots error proportions per state. You may optionally set a threshold value to only view states above a certain proportion of error. Bar labels are error counts.


```r
errorPlot_states(DL1301_proofed)
```

<img src="figure/errorplotstates-1.png" title="Figure 5. Plot of proportion of error by state." alt="Figure 5. Plot of proportion of error by state." width="500" style="display: block; margin: auto;" />

### errorPlot_dl

This function should not be used unless you want to visualize an entire season of data. The `errorPlot_dl` function plots proportion of error per download cycle across the year. Location may be specified to see a particular state over time.


```r
errorPlot_dl(hipdata2020, loc = "MI")
```

<img src="image/errorPlot_dl.png" title="errorPlot_dl example output" alt="errorPlot_dl example output" width="70%" style="display: block; margin: auto;" />

### errorTable

The `errorTable` function is a flexible way to obtain error data as a tibble, which can be assessed as needed or exported to create records of download cycle errors. The basic function reports errors by both location and field.


```r
errorTable(DL1301_proofed)
```

```
## # A tibble: 92 × 3
##    dl_state error           error_count
##    <chr>    <chr>                 <dbl>
##  1 AK       issue_date                1
##  2 AK       registration_yr           1
##  3 AL       birth_date              157
##  4 AL       email                     3
##  5 AL       firstname                 5
##  6 AL       registration_yr        4790
##  7 AL       suffix                    5
##  8 AL       zip                      10
##  9 CA       birth_date              212
## 10 CA       title                     2
## # … with 82 more rows
```

Errors can be reported by only location by turning off the `field` parameter.


```r
errorTable(DL1301_proofed, field = "none")
```

```
## # A tibble: 28 × 2
##    dl_state error_count
##    <chr>          <dbl>
##  1 AK                 2
##  2 AL              4970
##  3 CA               214
##  4 CO                77
##  5 CT               257
##  6 FL               103
##  7 GA               122
##  8 IA               147
##  9 ID               222
## 10 IN                71
## # … with 18 more rows
```

Errors can be reported by only field by turning off the `loc` parameter.


```r
errorTable(DL1301_proofed, loc = "none")
```

```
## # A tibble: 12 × 2
##    error           error_count
##    <chr>                 <dbl>
##  1 birth_date             2347
##  2 city                      1
##  3 email                   274
##  4 firstname                49
##  5 hunt_mig_birds           11
##  6 issue_date                1
##  7 lastname                  5
##  8 registration_yr        6591
##  9 state                     1
## 10 suffix                   37
## 11 title                     3
## 12 zip                     132
```

Location can be specified.


```r
errorTable(DL1301_proofed, loc = "CA")
```

```
## # A tibble: 2 × 3
##   dl_state error      error_count
##   <chr>    <chr>            <dbl>
## 1 CA       birth_date         212
## 2 CA       title                2
```

Field can be specified.


```r
errorTable(DL1301_proofed, field = "suffix")
```

```
## # A tibble: 1 × 2
##   error  error_count
##   <chr>        <dbl>
## 1 suffix          37
```

Total errors for a location can be pulled.


```r
errorTable(DL1301_proofed, loc = "CA", field = "none")
```

```
## # A tibble: 1 × 2
##   dl_state total_errors
##   <chr>           <dbl>
## 1 CA                214
```

Total errors for a field in a particular location can be pulled.


```r
errorTable(DL1301_proofed, loc = "CA", field = "dove_bag")
```

```
## # A tibble: 0 × 3
## # … with 3 variables: dl_state <chr>, error <chr>, error_count <dbl>
```

### redFlags

<b>By state.</b>
States with an unacceptable level of error can be pulled into a tibble. The tibble contains information pertaining to state, the count of errors from that state, the number of correct records from that state, the proportion of error per state, and a "flag" column that prints the threshold used. Any threshold can be supplied; in this example, we see which states had more than 3% error.


```r
redFlags(DL1301_proofed, type = "state", threshold = 0.03)
```

```
## # A tibble: 3 × 5
##   dl_state count_errors count_correct proportion flag        
##   <chr>           <int>         <int>      <dbl> <chr>       
## 1 AL               4970        114780     0.0415 error > 0.03
## 2 CT                257          5943     0.0415 error > 0.03
## 3 LA               1842         43158     0.0409 error > 0.03
```

<b>By field.</b>
The same can be done for data fields. In this example, we see which fields had more than 1% error.


```r
redFlags(DL1301_proofed, type = "field", threshold = 0.01)
```

```
## # A tibble: 2 × 5
##   errors          count_errors count_correct proportion flag        
##   <chr>                  <int>         <int>      <dbl> <chr>       
## 1 registration_yr         6591         41862     0.136  error > 0.01
## 2 birth_date              2347         46106     0.0484 error > 0.01
```

## Troubleshooting

### Common read_hip warnings

Sometimes `read_hip` will throw one or more warnings. Warnings are usually benign, but for clarity I provide examples and explanations of common warnings below. If the warning or error you receive after reading HIP data isn't described here and seems like a real problem, please [report an issue](#other).

#### Example 1

This parsing failure occurs when a .txt file is missing the last two columns in the fixed-width file (registration_yr and email). For the offending file(s), these columns are filled with NA in the output tibble. No action must be taken.

<img src="image/parsing_failure_1.png" title="Example 1. Common warning that results after running read_hip with missing columns in fixed-width text files." alt="Example 1. Common warning that results after running read_hip with missing columns in fixed-width text files." width="60%" style="display: block; margin: auto;" />

#### Example 2

Another version of a parsing failure occurs when a file is missing the last column in last row of the fixed-width file. This value is set to NA in the output tibble. No action must be taken.

<img src="image/parsing_failure_2.png" title="Example 2. Common warning that results after running read_hip with a missing column in one row of a fixed-width text file." alt="Example 2. Common warning that results after running read_hip with a missing column in one row of a fixed-width text file." width="60%" style="display: block; margin: auto;" />

### Memory problems

Some of these functions require a lot of memory to run. To help your R session process these data, especially when working with the large season totals, you can do a few things:

1. Remove objects from the environment. If you have already run `read_hip`, `clean`, and `proof`, you may no longer need your original dataframe or your cleaned dataframe, since most error checking functions work from the proofed or corrected versions of the data. To remove an unneeded object like the cleaned dataframe, run `rm(DL1301_clean)`.

2. Check your memory using `memory.limit()`

3. Increase your memory, e.g. `memory.limit(size = 55000)`

### Other

<b>Issue reporting</b>

If you find a bug in the package, it's advised to [create an issue](https://github.com/USFWS/migbirdHIP/issues) at the package's GitHub repo, https://github.com/USFWS/migbirdHIP.

<b>Questions?</b>

Contact Abby Walter, abby_walter@fws.gov

